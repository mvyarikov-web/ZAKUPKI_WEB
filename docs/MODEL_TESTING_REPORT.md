# Отчёт о тестировании моделей OpenAI

**Дата:** 29 октября 2025 г.

## Резюме

Проведено автоматическое тестирование всех моделей из конфигурации `index/models.json` с использованием реального API ключа OpenAI.

### Результаты тестирования

#### ✅ Рабочие модели (3):

1. **gpt-4o**
   - Статус: ✅ Работает корректно
   - Время ответа: ~2.1-2.5s
   - Оптимальный timeout: 20s (обновлено с 30s)
   - System role: да
   - Токены: 76 (60 вход, 16 выход)
   - Параметры: temperature=0.3, max_tokens

2. **gpt-4o-mini**
   - Статус: ✅ Работает корректно
   - Время ответа: ~1.8-2.6s
   - Оптимальный timeout: 20s (без изменений)
   - System role: да
   - Токены: 76-81 (60 вход, 16-21 выход)
   - Параметры: temperature=0.3, max_tokens
   - Примечание: самая быстрая модель

3. **o1**
   - Статус: ✅ Работает корректно
   - Время ответа: ~4.1-4.9s
   - Оптимальный timeout: 24s (обновлено с 90s)
   - System role: нет (reasoning-модель)
   - Токены: 205 (55 вход, 150 выход)
   - Параметры: max_completion_tokens (без temperature)
   - Примечание: ответ обрезан (finish_reason: length)

#### ❌ Удалённые модели (1):

1. **o1-mini**
   - Статус: ❌ 401 Unauthorized
   - Причина: `You have insufficient permissions for this operation`
   - Действие: удалена из конфигурации
   - Примечание: требуется более высокий уровень подписки OpenAI

## Внесённые изменения

### Обновлена конфигурация `index/models.json`:

1. **Удалена модель:** `o1-mini` (нет доступа)
2. **Обновлены timeout:**
   - `gpt-4o`: 30s → 20s
   - `o1`: 90s → 24s
3. **Изменён default_model:** `o1-mini` → `gpt-4o`

### Созданные файлы:

1. **`.env.example`** - шаблон для переменных окружения
2. **`tests/test_models_api.py`** - автоматические тесты моделей
3. **`index/models.json.backup`** - резервная копия конфигурации

## Рекомендации

1. **Оптимизация timeout:**
   - Текущие значения подобраны с запасом (3x от реального времени)
   - Для production можно снизить до 2x при стабильном соединении

2. **Модель o1:**
   - Ответ обрезается по длине (150 токенов)
   - Рекомендуется увеличить `max_completion_tokens` до 300-500 для полных ответов
   - Время ответа значительно выше других моделей

3. **По умолчанию:**
   - Установлена `gpt-4o` как default_model
   - Для массовых операций рекомендуется `gpt-4o-mini` (быстрее и дешевле)
   - Для сложной логики - `o1` (если требуется reasoning)

4. **Доступ к моделям:**
   - Модель `o1-mini` требует повышения уровня подписки
   - Проверьте доступ к другим моделям семейства o1/o3/o4 при необходимости

## Технические детали

### Параметры запросов:

- **gpt-4o, gpt-4o-mini:**
  - temperature: 0.3
  - max_tokens: 150
  - Поддержка system role: да

- **o1:**
  - temperature: не используется (только default=1)
  - max_completion_tokens: 150
  - Поддержка system role: нет

### Тестовый промпт:

```
System: "Ты - помощник для анализа документов закупок. Отвечай на русском языке кратко."
User: "Проанализируй этот текст и скажи главное: Поставка климатического оборудования 
включает 2 кондиционера мощностью 5 кВт."
```

## Следующие шаги

1. ✅ Автоматическое тестирование выполнено
2. ✅ Нерабочие модели удалены
3. ✅ Оптимальные параметры применены
4. ✅ Конфигурация обновлена
5. ✅ Верификация пройдена

**Система готова к использованию с проверенными моделями.**
