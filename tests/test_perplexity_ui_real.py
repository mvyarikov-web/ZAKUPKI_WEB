#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–†–µ–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç UI-–∑–∞–ø—Ä–æ—Å–∞ —Å "–ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å" –∫ Perplexity Sonar.

–ò–º–∏—Ç–∏—Ä—É–µ—Ç —Ç–æ—á–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã:
- HTTP POST /ai_rag/analyze —Å —Ä–µ–∞–ª—å–Ω—ã–º —Å–µ—Ä–≤–µ—Ä–æ–º
- force_web_search=True, clear_document_context=True
- search_params –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –º–æ–¥–µ–ª–∏
- –†–µ–∞–ª—å–Ω—ã–π API –∫–ª—é—á Perplexity

–¶–µ–ª—å: –¥–æ–±–∏—Ç—å—Å—è —Ç–∞–∫–æ–≥–æ –∂–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞, –∫–∞–∫ –≤ test_perplexity_real_search.py
"""
import pytest
import os
import sys
import requests
from pathlib import Path

# –ë–∞–∑–æ–≤—ã–π URL –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
BASE_URL = "http://localhost:8081"

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path
ROOT = Path(__file__).parent.parent
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))


def _has_perplexity_key() -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–∞ Perplexity."""
    if os.environ.get('PPLX_API_KEY') or os.environ.get('PERPLEXITY_API_KEY'):
        return True
    try:
        from utils.api_keys_manager_multiple import get_api_keys_manager_multiple
        mgr = get_api_keys_manager_multiple()
        key = mgr.get_key('perplexity')
        return bool(key)
    except Exception:
        return False


@pytest.mark.skipif(
    not _has_perplexity_key(),
    reason='–ù–µ—Ç –∫–ª—é—á–∞ Perplexity (–Ω–∏ –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏, –Ω–∏ –≤ –º–µ–Ω–µ–¥–∂–µ—Ä–µ api_keys)'
)
def test_ui_real_search_with_new_request():
    """
    –†–µ–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç: –ø–æ–ª–Ω–∞—è –∏–º–∏—Ç–∞—Ü–∏—è UI-–∑–∞–ø—Ä–æ—Å–∞ —Å "–ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å".
    
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
    1. force_web_search –∏ clear_document_context –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è
    2. search_params –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    3. –ú–æ–¥–µ–ª—å –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π –≤–µ–±-–ø–æ–∏—Å–∫ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–Ω–µ–∫–¥–æ—Ç—ã
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω
    try:
        health = requests.get(f"{BASE_URL}/health", timeout=5)
        if health.status_code != 200:
            pytest.skip(f"–°–µ—Ä–≤–µ—Ä –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ {BASE_URL}/health")
    except Exception as e:
        pytest.skip(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É: {e}")
    
    # –î–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å–∞ (—Ç–æ—á–Ω–æ –∫–∞–∫ –∏–∑ UI —Å "–ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
    request_data = {
        "file_paths": [
            "Documents_5666261/–°–≤–µ–¥–µ–Ω–∏—è –æ–± —É—Å–ª–æ–≤–∏—è—Ö –ø—Ä–æ–µ–∫—Ç–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ –∏ –≥—Ä–∞—Ñ–∏–∫–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –µ–≥–æ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤ 11445932 2025 09 23-14 01 (–ú–°–ö).docx"
        ],
        "prompt": "–ó–∞–π–¥–∏ –Ω–∞ —Å–∞–π—Ç https://www.anekdot.ru/ –∏ –Ω–∞–π–¥–∏ 3 —Å–≤–µ–∂–∏—Ö –∞–Ω–µ–∫–¥–æ—Ç–∞ –ø—Ä–æ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—é",
        "model_id": "sonar",
        "top_k": 0,  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        "max_output_tokens": 2500,
        "temperature": 0.2,
        "usd_rub_rate": 95.0,
        "search_enabled": True,
        "search_params": {
            "max_results": 8,
            "search_domain_filter": ["anekdot.ru"],  # –ë–µ–∑ www
            "search_recency_filter": "week",
            "return_related_questions": False,
            "language_preference": "ru",
        },
        "force_web_search": True,      # ‚úÖ –ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        "clear_document_context": True  # ‚úÖ –ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    }
    
    print("=" * 80)
    print("üß™ –†–ï–ê–õ–¨–ù–´–ô –¢–ï–°–¢: UI-–ø—É—Ç—å —Å force_web_search=True")
    print("=" * 80)
    
    print(f"\nüìã –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å:")
    print(f"  ‚Ä¢ URL: {BASE_URL}/ai_rag/analyze")
    print(f"  ‚Ä¢ model_id: {request_data['model_id']}")
    print(f"  ‚Ä¢ force_web_search: {request_data['force_web_search']}")
    print(f"  ‚Ä¢ clear_document_context: {request_data['clear_document_context']}")
    print(f"  ‚Ä¢ search_params: {request_data['search_params']}")
    print(f"  ‚Ä¢ prompt: {request_data['prompt'][:60]}...")
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
    response = requests.post(
        f"{BASE_URL}/ai_rag/analyze",
        json=request_data,
        timeout=90
    )
    
    print(f"\nüìä –°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {response.status_code}")
    
    assert response.status_code == 200, f"–û–∂–∏–¥–∞–ª—Å—è —Å—Ç–∞—Ç—É—Å 200, –ø–æ–ª—É—á–µ–Ω {response.status_code}"
    
    # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
    data = response.json()
    
    print(f"\nüì¶ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞:")
    print(f"  ‚Ä¢ success: {data.get('success')}")
    print(f"  ‚Ä¢ message: {data.get('message', '')[:100]}")
    
    assert data.get('success'), f"success=False: {data.get('message')}"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result = data.get('result', {})
    answer = result.get('answer', '')
    
    print(f"\nüìù –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ ({len(answer)} —Å–∏–º–≤–æ–ª–æ–≤):")
    print(f"{answer[:400]}...")
    
    # –ö–õ–Æ–ß–ï–í–´–ï –ü–†–û–í–ï–†–ö–ò: –º–æ–¥–µ–ª—å –ù–ï –¥–æ–ª–∂–Ω–∞ –æ—Ç–∫–∞–∑—ã–≤–∞—Ç—å—Å—è
    forbidden_phrases = [
        "–Ω–µ –º–æ–≥—É –∑–∞—Ö–æ–¥–∏—Ç—å –Ω–∞ –≤–Ω–µ—à–Ω–∏–µ —Å–∞–π—Ç—ã",
        "–Ω–µ –º–æ–≥—É –∑–∞–π—Ç–∏ –Ω–∞ –≤–Ω–µ—à–Ω–∏–µ —Å–∞–π—Ç—ã",
        "cannot access external links",
        "–Ω–µ –∏–º–µ—é –¥–æ—Å—Ç—É–ø–∞ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É",
        "–Ω–µ –º–æ–≥—É –æ—Ç–∫—Ä—ã–≤–∞—Ç—å —Å—Å—ã–ª–∫–∏",
        "–Ω–µ –º–æ–≥—É –Ω–∞–ø—Ä—è–º—É—é –∑–∞—Ö–æ–¥–∏—Ç—å"
    ]
    
    answer_lower = answer.lower()
    for phrase in forbidden_phrases:
        if phrase in answer_lower:
            pytest.fail(
                f"‚ùå –ü–†–û–í–ê–õ: –ú–æ–¥–µ–ª—å –æ—Ç–∫–∞–∑–∞–ª–∞—Å—å –≤—ã–ø–æ–ª–Ω—è—Ç—å –ø–æ–∏—Å–∫!\n"
                f"–ù–∞–π–¥–µ–Ω–∞ —Ñ—Ä–∞–∑–∞: '{phrase}'\n"
                f"–û—Ç–≤–µ—Ç: {answer[:300]}"
            )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞–Ω–µ–∫–¥–æ—Ç–æ–≤
    search_indicators = [
        "–∞–Ω–µ–∫–¥–æ—Ç",
        "–ø—Å–∏—Ö–æ–ª–æ–≥"
    ]
    
    found_indicators = [ind for ind in search_indicators if ind in answer_lower]
    
    print(f"\nüîé –ü—Ä–∏–∑–Ω–∞–∫–∏ —É—Å–ø–µ—à–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:")
    if found_indicators:
        print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω—ã: {', '.join(found_indicators)}")
    else:
        print(f"  ‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω—ã —è–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∞–Ω–µ–∫–¥–æ—Ç–æ–≤")
    
    # Usage
    usage = result.get('usage', {})
    print(f"\nüìä Usage:")
    print(f"  ‚Ä¢ total_tokens: {usage.get('total_tokens')}")
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
    assert len(found_indicators) > 0, "–û—Ç–≤–µ—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∞–Ω–µ–∫–¥–æ—Ç–æ–≤ –∏–ª–∏ –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏"
    
    print(f"\n‚úÖ –£–°–ü–ï–•: –ú–æ–¥–µ–ª—å –≤—ã–ø–æ–ª–Ω–∏–ª–∞ —Ä–µ–∞–ª—å–Ω—ã–π –≤–µ–±-–ø–æ–∏—Å–∫!")
    print(f"–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Å–∞–π—Ç–∞.")
    
    return True


if __name__ == '__main__':
    # –ü—Ä—è–º–æ–π –∑–∞–ø—É—Å–∫
    test_ui_real_search_with_new_request()
