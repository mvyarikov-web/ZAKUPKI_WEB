# Автоматическое тестирование моделей OpenAI

## Описание

Модуль `test_models_api.py` обеспечивает автоматическое тестирование всех моделей из конфигурации `index/models.json` с использованием реального API OpenAI.

## Возможности

- ✅ Проверка доступности каждой модели
- ✅ Автоматический подбор оптимальных параметров (timeout, temperature, max_tokens)
- ✅ Определение поддержки system role
- ✅ Автоматическое исправление проблемных моделей (смена параметров)
- ✅ Удаление недоступных моделей из конфигурации
- ✅ Создание backup перед изменениями
- ✅ Подробный отчёт о результатах

## Требования

```bash
pip install pytest openai python-dotenv
```

## Настройка

1. Создайте файл `.env` в корне проекта:

```bash
cp .env.example .env
```

2. Добавьте ваш OpenAI API ключ в `.env`:

```env
OPENAI_API_KEY=sk-your-api-key-here
```

⚠️ **Важно:** Файл `.env` автоматически игнорируется git и не будет закоммичен.

## Запуск тестов

### Полный запуск всех тестов:

```bash
pytest tests/test_models_api.py -v -s
```

### Только проверка доступности моделей:

```bash
pytest tests/test_models_api.py::TestModelAvailability::test_all_models_accessible -v -s
```

### Только подбор оптимальных параметров:

```bash
pytest tests/test_models_api.py::TestModelOptimalParams::test_optimal_timeout -v -s
```

### Только очистка нерабочих моделей:

```bash
pytest tests/test_models_api.py::TestModelCleanup::test_remove_broken_models -v -s
```

## Что делают тесты

### 1. TestModelAvailability

Проверяет каждую модель из `models.json`:
- Отправляет тестовый запрос
- Проверяет корректность ответа
- При ошибках пытается автоматически исправить (изменить параметры)
- Логирует результаты

### 2. TestModelOptimalParams

Анализирует время ответа моделей и рекомендует оптимальный timeout:
- Измеряет фактическое время ответа
- Рассчитывает оптимальный timeout (3x от времени ответа + запас)
- Сохраняет рекомендации для обновления конфигурации

### 3. TestModelCleanup

Обновляет конфигурацию на основе результатов тестов:
- Создаёт backup `index/models.json.backup`
- Удаляет недоступные модели
- Применяет оптимальные параметры
- Обновляет `default_model` при необходимости

## Результаты

После выполнения тестов:

1. **Обновлённая конфигурация:** `index/models.json` содержит только рабочие модели с оптимальными параметрами

2. **Резервная копия:** `index/models.json.backup` содержит исходную конфигурацию

3. **Детальный отчёт:** Выводится в консоль с информацией о каждой модели

4. **Документация:** `docs/MODEL_TESTING_REPORT.md` содержит полный отчёт о тестировании

## Примеры результатов

```
============================================================
Тестирование модели: gpt-4o (GPT-4o)
============================================================
✅ Модель gpt-4o работает корректно
   Время ответа: 2.45s
   Токены: 76 (вход: 60, выход: 16)
   Finish reason: stop
   Ответ (первые 100 символов): Поставка включает 2 кондиционера...

============================================================
ИТОГОВЫЙ ОТЧЁТ
============================================================

✅ Рабочие модели (3):
   • gpt-4o
     - Время ответа: 2.45s
     - Timeout: 20s
     - System role: да
   • gpt-4o-mini
     - Время ответа: 2.55s
     - Timeout: 20s
     - System role: да
   • o1
     - Время ответа: 4.86s
     - Timeout: 24s
     - System role: нет

❌ Нерабочие модели (1):
   • o1-mini: Error code: 401 - insufficient permissions
```

## Тестовый промпт

Тесты используют следующий промпт для проверки моделей:

```
System: "Ты - помощник для анализа документов закупок. Отвечай на русском языке кратко."
User: "Проанализируй этот текст и скажи главное: Поставка климатического оборудования 
включает 2 кондиционера мощностью 5 кВт."
```

## Обработка ошибок

Тесты автоматически обрабатывают распространённые ошибки:

- **401 Insufficient permissions:** Модель удаляется (требуется доступ)
- **Temperature error:** Пробуется запрос без system role
- **Max_tokens error:** Переключается на max_completion_tokens
- **Model not found (404):** Модель удаляется (устарела)

## Безопасность

- ✅ Файл `.env` с API ключом в `.gitignore`
- ✅ Пример конфигурации в `.env.example` без реальных ключей
- ✅ Автоматическое создание backup перед изменениями
- ✅ Логирование всех операций

## Интеграция с CI/CD

Тесты можно интегрировать в CI/CD pipeline:

```yaml
# .github/workflows/test-models.yml
name: Test OpenAI Models
on:
  schedule:
    - cron: '0 0 * * 0'  # Каждое воскресенье
  workflow_dispatch:  # Ручной запуск

jobs:
  test-models:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      - name: Run model tests
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          pytest tests/test_models_api.py -v
```

## Дополнительная информация

- **Отчёт о последнем тестировании:** `docs/MODEL_TESTING_REPORT.md`
- **Конфигурация моделей:** `index/models.json`
- **Резервная копия:** `index/models.json.backup`

## Поддержка

При возникновении проблем:

1. Проверьте корректность API ключа в `.env`
2. Убедитесь, что у вас есть доступ к моделям
3. Проверьте логи в консоли для деталей ошибок
4. Восстановите конфигурацию из backup при необходимости:
   ```bash
   cp index/models.json.backup index/models.json
   ```
