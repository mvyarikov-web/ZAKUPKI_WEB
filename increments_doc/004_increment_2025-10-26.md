# Постановка

## Цель инкремента
Внедрить RAG-систему (Retrieval-Augmented Generation) для углубленного анализа документов закупок климатической техники. Обеспечить ответы на основе документов (а не «из головы» модели) с минимальными затратами токенов и управлением стоимости. Система должна выдавать:
- Краткую выжимку по документам (summary);
- Полный список оборудования с характеристиками (equipment[]);
- Вердикт «требуется ли монтаж» с краткими цитатами-обоснованиями (installation.verdict + evidence[]).

## Контекст интеграции
RAG-модуль будет **дополнять**, но **не заменять** существующий функционал проекта:
- **Существующий поиск по индексу** (`_search_index.txt`, ключевые слова, сниппеты) остаётся доступен как базовый инструмент.
- **RAG-модуль** работает поверх того же индекса, используя векторную индексацию (эмбеддинги) для семантического ретривала и более глубокого анализа через LLM.
- Пользователь может выбирать: классический поиск (быстрый, бесплатный) или AI-анализ с RAG (глубокий, платный, через OpenAI).

## Связь с архитектурой проекта
- **База**: Flask-приложение (Python 3.9+), модульная структура (`webapp/`, `document_processor/`), логи в `logs/`, индексы в `index/`, файлы в `uploads/`.
- **Индексация**: RAG будет использовать существующую экстракцию текста (`document_processor/search/indexer.py`), но добавит:
  - Чанкование текста на фрагменты 1500–3000 токенов с overlap.
  - Векторные эмбеддинги для семантического поиска (pgvector в PostgreSQL).
  - Метаданные: doc_id, file_name, page_range, hash, source_path.
- **UI**: новая секция «AI-анализ (RAG)» параллельно существующей «Анализ ИИ» (OpenAI простой); использует чекбоксы для выбора документов, выбор модели, настройки промпта и Top-K.
- **Бэкенд**: новый Blueprint `ai_rag.py` в `webapp/routes/`, новый сервис `webapp/services/rag_service.py`, таблицы в PostgreSQL (уже есть DBeaver-конфигурация).

## Пользовательский сценарий
1. Пользователь отмечает чекбоксами нужные документы (предварительно загруженные и проиндексированные через существующий механизм `/upload` → `/build_index`).
2. Переходит в раздел «AI-анализ (RAG)» и нажимает «Анализ AI».
3. Видит поле промпта (редактируемое, сохраняется «последний использованный»), предварительный подсчёт токенов и примерную цену запроса для выбранных документов.
4. Рядом с кнопкой «Оптимизировать текст» доступна кнопка «Модель»: в ней перечислены доступные модели для ключа GPT и поля ручного ввода цен за входные/выходные токены (по умолчанию 0). Введённые значения сохраняются и используются далее в расчётах.
5. Система показывает оценку запроса (токены и стоимость) без каких-либо блокировок по лимитам; при необходимости сервис сам подбирает количество фрагментов (Top-K), чтобы поместиться в контекст.
6. По кнопке «Начать анализ» выполняется полноценный RAG:
  - Релевантные чанки находятся семантическим векторным поиском (с опцией гибридного режима: ключевые слова/BM25).
  - Контекст собирается из Top-K фрагментов (3–8 по умолчанию) и промпта пользователя.
  - Отправляется один запрос к LLM с требованием структурированного ответа (summary, equipment[], installation).
7. Пользователь получает результат:
  - summary (до 10 пунктов);
  - equipment[] с полями: name, model, characteristics{key:value}, qty, unit, evidence[];
  - installation: {verdict: true|false|unknown, evidence[]} (evidence — короткие цитаты + doc_id/page);
  - Фактический расход токенов (input/output/total) и реальную стоимость по выбранной модели.

## Общее описание RAG-процесса
1. **Ингест**: преобразование документов в текст (используем существующий `document_processor/search/indexer.py`), чистка и разметка метаданных.
2. **Индексация (новое)**: 
   - Разбиение текста на чанки (1500–3000 токенов, overlap 2–3 предложения).
   - Вычисление эмбеддингов для каждого чанка (OpenAI `text-embedding-3-small` или аналог).
   - Сохранение в векторный индекс (pgvector в PostgreSQL).
3. **Ретривал (поиск)**: 
   - По вопросу/промпту вычисляем эмбеддинг.
   - Извлекаем 3–8 наиболее релевантных чанков (косинусная близость + опциональный BM25 для гибрида).
4. **Сборка запроса**: 
   - Формируется компактный контекст из найденных чанков + промпт пользователя.
   - Контроль бюджета: системные инструкции + промпт + чанки + ожидаемый ответ ≤ context_window_tokens.
5. **Генерация**: 
   - Модель (GPT-4, GPT-4.1-mini и др.) формирует структурированный ответ (summary, equipment[], installation).
6. **Постобработка**: 
   - Дедупликация оборудования (по name+model).
   - Агрегация вердикта монтажа.
   - Подсчёт фактических токенов (input/output) и стоимости.
   - Подготовка итоговых файлов/полей для UI.


# Спецификация

## Область изменений
- **Бэкенд**: 
  - `webapp/routes/ai_rag.py` — новый Blueprint для RAG-эндпоинтов.
  - `webapp/services/rag_service.py` — логика векторного поиска, чанкования, обращения к OpenAI.
  - `webapp/models/` — модели данных (при необходимости).
  - `index/models.json` — локальное хранилище списка моделей и ручных цен (MVP; БД-таблица опционально позже).
- **База данных**: 
  - Таблицы в PostgreSQL: `documents`, `chunks` (векторные embeddings через pgvector).
  - Установка расширения `pgvector` для векторного поиска.
- **UI**: 
  - `templates/index.html` — новая секция «AI-анализ (RAG)» с чекбоксами, промптом, кнопкой «Модель» (ручной ввод цен), оценкой и результатами.
  - `static/js/ai-rag.js` — клиентская логика для RAG-интерфейса, выбор модели и сохранение цен.
- **Существующие модули**: 
  - `document_processor/search/indexer.py` — переиспользование извлечения текста (без изменений).
  - `webapp/services/gpt_analysis.py` — может быть расширен или создан отдельный `rag_llm_client.py`.

## Функциональные требования

### 1. Интерфейс (минимально)
**Экран «AI-анализ (RAG)»** (новый раздел в UI):
- Поле «Промпт» (многострочное textarea; сохраняется «последний использованный»).
- Список документов с чекбоксами (переиспользовать существующий механизм выбора файлов).
- Кнопка «Модель» рядом с «Оптимизировать текст»: всплывающее окно со списком доступных моделей и двумя полями для ручного ввода цен — «Цена входных токенов» и «Цена выходных токенов» (по умолчанию 0). Введённые значения сохраняются и используются далее в расчётах; выбор модели тоже сохраняется.
- Поле «Ожидаемые выходные токены» (число, по умолчанию 600; допускается 0 для значения по умолчанию модели).
- **Блок «Оценка запроса»** (до отправки):
  - Input tokens (по выбранным Top-K фрагментам + промпт);
  - Expected output tokens;
  - Total tokens;
  - Estimated cost (рубли/доллары) — считается из введённых пользователем цен для выбранной модели; если цены равны 0, стоимость показывается как 0.
- Без лимита символов и индикатора «Fits»: UI не блокирует отправку из‑за длины; сервис сам регулирует Top‑K, чтобы помещаться в контекст модели.
- **Переключатели**:
  - RAG: вкл/выкл (по умолчанию вкл);
  - Top-K (слайдер 3–10, дефолт 5);
  - Гибридный поиск: вкл/выкл (семантика + ключевые слова, дефолт вкл);
  - «Прикрепить фрагменты» (опционально для MVP);
  - «Исключить разделы» (опционально для MVP).
- **Блок «Фактический расход»** (после ответа):
  - Input tokens (факт);
  - Output tokens (факт);
  - Total tokens (факт);
  - Actual cost (рубли/доллары) — по сохранённым ценам выбранной модели.
- Кнопка «Начать анализ» — запускает полный RAG.

**Экран «Настройки → Модели»** (новый):
- Редактируемая таблица моделей (CRUD):
  - model_id (str, уникальный);
  - display_name (str);
  - context_window_tokens (int);
  - price_input_per_1M (float, руб. или $);
  - price_output_per_1M (float);
  - enabled (bool, чекбокс).
- Кнопки: «Добавить модель», «Сохранить», «Удалить».
- По умолчанию заполнены модели: gpt-4-turbo, gpt-4.1-mini, gpt-3.5-turbo (с примерными ценами для старта).

### 2. Ингест и очистка (расширение существующей логики)
- **Переиспользовать** `document_processor/search/indexer.py` для извлечения текста из PDF/DOCX/XLS/TXT/HTML/CSV/TSV/XML/JSON.
- **Новая очистка** (в `rag_service.py` или отдельном модуле):
  - Убрать титулы, оглавления, листы согласований, повторяющиеся колонтитулы.
  - Нормализовать единицы (Вт/кВт, м³/ч) — упрощённая нормализация на основе регулярных выражений (полная конверсия — вне MVP).
  - Убрать дефисы/переносы, кодировки (уже делается в indexer.py через chardet).
- **Сохранить важное**:
  - Разделы «Требования», «Спецификация», «Монтаж», «ПНР», «Поставки».
  - Таблицы характеристик и сметы.
  - Номера пунктов, ссылки на ГОСТ/СНИП.
- **Метаданные** (для каждого чанка):
  - doc_id, file_name, page_range/section, hash, source_path.

### 3. Чанкование (индексация)
Размер чанка: ~1500–3000 токенов; overlap 2–3 предложения.
Делить по смыслу: заголовки/разделы/табличные строки, а не «посередине предложения».
Для табличных блоков — приводить строку в линейный вид «ключ: значение», не теряя единиц измерения.
Каждый чанк получает эмбеддинг и метаданные (см. п.5).
7) Векторный индекс и хранилище
Хранить в вашей существующей БД PostgreSQL через pgvector (рекомендуется, так как у вас уже планируется Postgres и DBeaver).
Таблицы:
documents (описание файла/версии),
chunks (текст, мета, вектор),
inverted_index/BM25 (по желанию для гибридного поиска).
Дедупликация: по hash чанка и/или MinHash для близнецов.
8) Ретривал (поиск релевантных фрагментов)
По входному промпту считаем эмбеддинг запроса; делаем Top-K по косинусной близости.
Гибридный режим (рекомендуется по умолчанию): семантика + ключевые слова (BM25) с синонимами: монтаж, установка, ПНР, шеф-монтаж, СМР, пусконаладка, монтажные работы и др.
Фильтры: порог релевантности; исключение «мусорных» разделов по метаданным.
Реранжирование (опционально): если совпадений много.
9) Формирование запроса к модели
Контекстный бюджет: суммарные токены системные инструкции + промпт пользователя + выбранные фрагменты + ожидаемый ответ ≤ context_window_tokens модели.
Подмешивать только Top-K фрагментов (3–8); если не помещается — снизить K.
Вывод требовать строго структурированный (например):
summary[] (до 10 пунктов),
equipment[] с полями: name, model?, characteristics{key:value}, qty?, unit?, evidence[],
installation: {verdict: true|false|unknown, evidence[]} (evidence — короткие цитаты + doc_id/page).
max_output_tokens: по умолчанию 400–600.
10) Постобработка и агрегация
Дедуп оборудования по ключу name+model (без учёта регистра/пробелов); слияние characteristics без перезаписи существующих ключей.
Вердикт «монтаж»:
если хоть в одном фрагменте уверенное подтверждение → true;
если во всех фрагментах явно «не требуется» → false;
иначе unknown.
Итоговый пакет для UI/экспорта:
краткая выжимка,
equipment.json (массив объектов),
вердикт с evidence[] (цитаты с привязкой к источнику).
11) Учёт токенов и стоимость (упрощённая схема)
До запроса: оценка input_tokens (по выбранным фрагментам + промпт), expected_output_tokens (из UI), estimated_cost — рассчитывается из вручную заданных цен для выбранной модели (значения могут быть 0 по умолчанию).
После запроса: показать фактические input/output/total tokens (из usage) и actual_cost по тем же ценам.
Хранение цен и моделей: локальный файл `index/models.json` (MVP). Опционально позже — таблица в БД и экран «Настройки → Модели».
12) Настройки (значения по умолчанию)
chunk_size_tokens = 2000, overlap_sentences = 3.
top_k = 5, min_similarity_threshold — «средний».
max_output_tokens = 600.
Модель по умолчанию: эконом-вариант (например, gpt-4.1-mini), переключаемая в UI.
Гибридный поиск: вкл (семантика + ключевые слова/синонимы).
Политика исключения: title, toc, approval_sheets, повторяющиеся колонтитулы.
Список синонимов для монтажа/ПНР — в словаре проекта (настраиваемый).
Ограничения по длине ввода в UI отключены; сервис сам уменьшает Top‑K при необходимости.
13) Логи и аудит
Логировать: model_id, top_k, выбранные chunk_ids, usage, оценка vs фактический расход, время ответа.
В результаты включать evidence с doc_id/page для проверки.
При желании — сохранять «моментальный снимок» промпта и подмешанных фрагментов (для воспроизводимости).
14) Критерии готовности (DoD)
В UI работает переключение модели и оценка стоимости до запроса.
RAG по одному клику возвращает summary, equipment[], installation с цитатами источников.
При одном и том же наборе документов и промпте результаты детерминированы в части состава evidence (при неизменных фрагментах).
В логах фиксируются фактические usage и сравнение с оценкой.
На тестовом наборе из 10–20 документов извлечение оборудования имеет приемлемую полноту, а вердикт «монтаж» — подтверждается цитатами.
15) Ограничения (осознанно вне объёма на этом этапе)
Автопарсинг цен моделей из интернета (цены вводятся вручную).
Полноценная нормализация единиц (конверсия Вт↔кВт и т.п. в общий стандарт).
Сложные табличные распознавания на уровне OCR (при необходимости — отдельным этапом).
16) Риски и меры
OCR-мусор → предусмотреть фильтры и ручное исключение разделов.
Тонкая терминология → гибридный поиск + словарь синонимов по монтажу/ПНР.
Переполнение контекста → авто‑снижение Top‑K и контроль max_output_tokens; без блокировки UI (опциональное предупреждение только информирует).
Дубли/версии → хеш-дедуп на этапе индексации.
17) Дорожная карта (минимальные шаги)
K1. Кнопка «Модель» и локальное хранение `index/models.json` с ручными ценами (по умолчанию 0), подсчёт стоимости в UI.
K2. Экран «Анализ»: блок «Оценка запроса» с токенами и стоимостью, без блокировки по лимитам.
K3. Ингест/очистка/чанкование + индексация в Postgres+pgvector.
K4. Ретривал (семантика + ключевые слова), Top-K, сборка контекста.
K5. Структурированный ответ + агрегатор (equipment, verdict, evidence).
K6. Логи usage и отчёт об оценке vs факт.