# increment-012 — Модуль анализа текста по сводному индексу (_search_index.txt)

Дата и время пуша (MSK): 2025-10-17 21:51:15
Git commit hash: be5e6b72b279d17f8bb53dbbed5cf3bbfb03fea9

## Постановка

Добавить в проект модуль анализа текста, который:
- Проводит оффлайн-анализ сводного индекса `_search_index.txt` (без повторной обработки исходных файлов).
- Извлекает структурированные поля закупки (наименование/предмет, номера/идентификаторы, даты, цена, адрес/место поставки, перечень объектов закупки с кодами ОКПД2/КОЗ/единицами/количествами, требования ТЗ/монтажа/гарантия и т. п.).
- Позволяет пользователю отредактировать извлечённые значения в UI перед сохранением.
- Формирует человекочитаемый HTML-отчёт и открывает его в новой вкладке; сохраняет JSON-результат рядом с индексом.
- Использует правила на основе регулярных выражений и, при наличии, spaCy (ru_core_news_sm) для устойчивого извлечения сущностей (организации, адреса, даты, денежные суммы). При отсутствии spaCy — graceful degrade на regex.
- Встраивается в текущую архитектуру (Flask blueprints, services, document_processor), не ломая существующий функционал и тесты.

Ограничения и допущения:
- Поиск и анализ выполняются только по готовому сводному индексу `index/_search_index.txt` (в UI — создание индекса отдельной кнопкой «Построить индекс» уже реализовано).
- Заголовки в индексе (разделители `====`, строки «ЗАГОЛОВОК:», «Формат:», «Источник:») игнорируются; анализ идёт по содержимому между маркерами `<<< НАЧАЛО ДОКУМЕНТА >>>` … `<<< КОНЕЦ ДОКУМЕНТА >>>` для каждого файла.
- OCR, разбор архивов и любые дорогие операции — этап индексации, не HTTP.

## Спецификация

### 1. Архитектура и размещение
- document_processor/analysis/
  - extractor.py — ядро извлечения: парсинг `_search_index.txt`, разметка документов, правила (regex), опциональный NLP (spaCy), агрегирование результатов.
  - schemas.py — pydantic-модели (или dataclasses) для структурированных сущностей: Procurement, Item, Party, Addresses, Terms.
- webapp/services/analysis.py — оркестрация: валидация входов, вызов `Extractor`, пост-обработка, сериализация JSON/HTML, пути сохранения.
- webapp/routes/analysis.py — Blueprint с REST-ручками:
  - POST /analysis/run — запустить анализ индекса, вернуть JSON с извлечёнными полями и подсветкой источников.
  - POST /analysis/save — принять отредактированные поля, сохранить JSON и HTML-отчёт; вернуть URL отчёта.
  - GET /analysis/report/<report_id> — отдать сохранённый HTML-отчёт (из папки `index/reports/`).
- templates/analysis_form.html — форма редактирования результатов анализа (Jinja2).
- templates/analysis_report.html — шаблон HTML-отчёта.
- static/js/analysis.js — логика запроса анализа, заполнение формы, отправка сохранения, открытие отчёта в новой вкладке.

Интеграция в текущие экраны:
- На главной странице (`templates/index.html`) в блок «Инструменты» добавить кнопку «Анализ текста» (visible, disabled, если нет индекса). Кнопка открывает модальное окно или отдельную страницу `/analysis` с формой.

### 2. Контракты данных (ввод/вывод)
Вход (POST /analysis/run):
- Параметры: нет или опциональные фильтры:
  - include_docs: список масок путей внутри индекса (по умолчанию все).
  - lang: "ru" (по умолчанию).
- Источник: путь к индексу определяется из конфига: `current_app.config['INDEX_FOLDER']/_search_index.txt`.

Выход (JSON):
- procurement: объект со сводными полями:
  - subject (str)
  - price (str|Decimal, исходный вид и нормализованное значение)
  - plan_registry_number (str) — например «Реестровый номер позиции ПЗ»
  - year (int)
  - contract_dates: { start: date|null, end: date|null }
  - customer: { name: str, inn: str|null, kpp: str|null, address: str|null }
  - supplier: { name: str|null, inn: str|null, kpp: str|null, address: str|null }
  - delivery_place: str|null
  - warranty: { months: int|null, text: str|null }
  - payment_terms: str|null
  - penalties: str|null
- items: массив объектов позиции закупки:
  - { okpd2: str|null, koz: str|null, name: str, qty: str|Decimal|null, uom: str|null, price: str|null }
- requirements: { installation: str|null, tech_spec: str|null, safety: str|null }
- sources: массив ссылок на документы в индексе с координатами (doc_id, offset_start, offset_end) для трассировки извлечения.
- meta: { analyzed_docs: int, skipped_docs: int, started_at, finished_at, nlp: { enabled: bool, model: str|null } }

Вход (POST /analysis/save):
- JSON с той же схемой, присланный из формы после правок пользователем.

Выход:
- { ok: true, report_url: "/analysis/report/<id>", saved_json: "index/reports/<id>.json" }

### 3. Правила извлечения
Источник: только `_search_index.txt` (из папки `index/` по конфигурации). Обработка документов последовательно; заголовочные блоки игнорируются.

Базовые regex-паттерны (неисчерпывающий список):
- Даты: `\b(\d{2}[./-]\d{2}[./-]\d{4})\b` с нормализацией в YYYY-MM-DD.
- Цена/суммы: числа с пробелами/неразрывными пробелами и запятой: `\b\d{1,3}(?:[\s\u00A0]\d{3})*(?:[.,]\d{2})?\b` и маркеры «руб», «рублей», «₽».
- ОКПД2: `\b\d{2}\.\d{2}\.\d{2}\.\d{3}\b` (вариативно).
- КОЗ: шаблоны вида `\b\d{2}\.\d{2}\.\d{2}\.\d{2}\.\d{2}\.\d{2}\.\d{2}\b` (варианты присутствуют в индексе).
- Реестровый номер позиции ПЗ: `Реестров[а-я ]+ПЗ[:\s]+([\d-]+)`.
- Год планирования: `Год планирован[ия|ия:]+\s*(\d{4})`.
- Ед. измерения (уом): из таблиц/рядов («Штука», «шт», «м2», и т. п.).
- Количество: числа/десятичные с фиксированными знаками.
- Адрес/место поставки: строки, начинающиеся с «Место поставки товара» либо содержащие индекс/город/улицу.
- Предмет/наименование договора: первой приоритет — строки «Предмет договора: …», «Предмет закупки: …», «Поставка …».
- Гарантия: «гарантийный срок», «гарантийного обслуживания», «месяц/месяцев».
- Условия оплаты/штрафы/пени: соответствующие заголовки разделов.

Опциональный NLP (spaCy):
- Модель ru_core_news_sm; использовать сущности ORG, DATE, MONEY, LOC/GPE; noun_chunks для названий предмета закупки.
- Включение — только если `import spacy` успешен и модель доступна. Иначе — логируем предупреждение и работаем на regex.

Объединение результатов:
- При наличии нескольких кандидатов выбирать по приоритетам: (1) точное совпадение по ключевой фразе заголовка, (2) близость к табличным маркерам (в строках «Сведения об объектах закупки»), (3) NLP-конфиденс, (4) первое упоминание.
- Для позиций items — парсить ряды вида: `код | наименование | цена | кол-во | ед.изм | …`. В индексах DOCX такие ряды попадают как текст — разбирать по разделителям `|`, `;`, множественным пробелам.

### 4. Валидация и ограничения
- Ограничить анализ до N документов (например, 500) за один запуск; при большем — предложить фильтр include_docs.
- Лимиты размеров: максимум 10 MB на `_search_index.txt` (конфигурируемо). При превышении — 413 с дружелюбным сообщением.
- Нормализация пробелов, удаление невидимых символов (NBSP, BOM), унификация регистров для поиска маркеров.
- Все результаты — в UTF-8. `app.config['JSON_AS_ASCII'] = False`.

### 5. UI и взаимодействие
- Страница анализа:
  - Кнопка «Запустить анализ» — вызывает POST /analysis/run.
  - Поля формы: заполняются результатами; пользователю доступны правки.
  - Кнопка «Сохранить и открыть отчёт» — POST /analysis/save; по успеху — открыть `report_url` в новой вкладке.
- Подсказки и подписи — на русском языке.
- Если индекса нет — показать нон-блокирующее предупреждение и предложить построить индекс.

### 6. Маршруты и безопасность
- Все пути файлов — через безопасные джойны и проверку подкаталогов (`index/` для результатов анализа). Без traversal.
- Ответы — JSON/HTML; ошибки — краткие и понятные (400/413/500), логирование через `app.logger`.
- Логи: начало/конец анализа, кол-во разобранных документов, включён ли NLP, тайминги.

### 7. Хранение артефактов
- JSON: `index/reports/<timestamp>_<shortid>.json` — полный срез результата.
- HTML: `index/reports/<timestamp>_<shortid>.html` — отчёт на основе `templates/analysis_report.html`.
- В JSON включать ссылку на HTML и наоборот (сквозная навигация).

### 8. Зависимости
- Обязательные: переиспользовать текущие (Flask, chardet и т. д.).
- Опциональные: spacy (>=3), модель `ru_core_news_sm`. Установка модели — оффлайн/по инструкции; при отсутствии — модуль работает в regex-режиме.
- Не тянуть тяжёлые зависимости автоматически (не добавлять загрузку модели в runtime HTTP). Описать установку в README (в отдельном приращении).

### 9. Тестирование (pytest)
Минимальный набор (по умолчанию быстрые тесты):
- tests/test_analysis_basic.py
  - test_parse_index_minimal() — из короткого `_search_index.txt` извлекаются предмет, даты, одна позиция, адрес.
  - test_no_spacy_graceful_degrade() — при отсутствии spaCy анализ проходит на regex, поля заполняются.
- tests/test_analysis_items_table.py — проверка разборки табличных строк с `|` и пробелами.
- tests/test_analysis_routes.py — e2e через Flask test client: /analysis/run и /analysis/save; проверка создания артефактов, кодов ответов, заголовков.
- tests/test_analysis_large_index_skip.py — скип при превышении лимита документов.

Метки:
- Тесты, требующие spaCy, помечать `@pytest.mark.skipif(not spacy_available, reason="spaCy not installed")`.
- Таймауты: использовать уже добавленную стратегию таймаутов (pytest-timeout и/или signal) на 30 секунд.

### 10. Производительность
- Один проход по файлу индекса с потоковым чтением; избегать загрузки всего файла в память при размере >5 MB.
- Кэшировать предкомпилированные regex.
- NLP — отключаемый флаг в конфиге `ANALYSIS_USE_NLP` (по умолчанию True, но активируется только если зависимости доступны).

### 11. Конфигурация
- `INDEX_FOLDER` — уже присутствует (папка `index/`).
- Новые опции в `config.py` (безопасные дефолты):
  - ANALYSIS_MAX_DOCS = 500
  - ANALYSIS_MAX_INDEX_SIZE_MB = 10
  - ANALYSIS_USE_NLP = True
  - ANALYSIS_REPORTS_SUBDIR = "reports"

### 12. Миграция и обратная совместимость
- Все изменения изолированы в новых файлах/шаблонах/статике.
- Существующие ручки и шаблоны не ломаются; добавляется только новый раздел UI и новый Blueprint.
- При отсутствии индекса — поведение неизменно; кнопка анализа неактивна или показывает подсказку.

### 13. Логирование и мониторинг
- INFO: старт/финиш, кол-во документов, длительность, включён ли NLP.
- DEBUG: срабатывание ключевых паттернов, укороченные сниппеты источников.
- ERROR: исключения с `logger.exception`.

### 14. Риски и меры
- Тяжёлые зависимости (spaCy): mitigated через optional и graceful degrade.
- Вариативность формулировок в документах: гибкие regex + fallback стратегии; ручное редактирование в UI перед сохранением.
- Большие индексы: лимиты и фильтры.

## Реализация (простыми словами)
1) Разбираем `_search_index.txt`, вычленяем чистый текст документов между маркерами, игнорируя заголовки.
2) Прогоняем набор предкомпилированных regex для дат, цен, ОКПД2, предмета, адреса, гарантий и т. п.; если есть spaCy — дополняем извлечённые сущности.
3) Собираем объект Procurement + Items + Requirements, сохраняем источники (doc_id/offset) для трассировки.
4) Отдаём JSON в форму; пользователь при необходимости поправляет поля.
5) Сохраняем JSON и рендерим HTML-отчёт; открываем отчёт в новой вкладке.

## Примечания
- Полные инструкции по установке spaCy и модели будут добавлены отдельным приращением документации.
- В отчёте предусмотреть раздел «Источники» со списком документов и цитатами, на основании которых извлечены поля (для верификации).
