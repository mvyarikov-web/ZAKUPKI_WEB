
Предыдущая стабильная версия - Хеш коммита:
24f6b61221531ef898c8763869d230d2132308ad

**Коммит increment 013 (шаги 1-6):**
c7797d32f138dc1f71d3930c1d424b517ac17371
Дата: 04.11.2025 (MSK)


# ТЗ: Первичный переход на PostgreSQL с многопользовательской архитектурой

## 0) Контекст и критические требования

**ТЕКУЩЕЕ СОСТОЯНИЕ:**
* ❌ БД НЕ ИСПОЛЬЗУЕТСЯ — всё хранится в файлах (`uploads/`, `index/*.json`, `logs/*.log`)
* ❌ Однопользовательский режим — нет разделения данных между пользователями
* ❌ Запросы и ответы НЕ СОХРАНЯЮТСЯ — нет истории работы
* ❌ Дублирование кода — множественные обработчики файлов, индексов

**ЦЕЛИ МИГРАЦИИ:**

1. **Полный переход на PostgreSQL** — всё состояние (документы, логи, настройки, ключи) в БД
2. **Многопользовательская архитектура** — каждый пользователь видит только свои данные
3. **История работы** — все запросы, ответы, действия логируются и доступны
4. **Упрощение кода** — единый DAL, убрать файловые операции, устранить дубли
5. **Масштабируемость** — готовность к ≥50k документов, ≥100 пользователей

**КРИТЕРИИ УСПЕХА:**

* ✅ Приложение работает БЕЗ директорий `uploads/`, `index/`, `logs/` (всё в БД)
* ✅ Регистрация/вход пользователей + JWT-авторизация
* ✅ Каждый пользователь видит только свои документы, ключи, модели, историю
* ✅ Все запросы к AI и результаты сохраняются с привязкой к пользователю
* ✅ Миграция существующих файлов в БД без потери данных
* ✅ UI остаётся прежним (добавляются: логин, профиль, история запросов)
* ✅ Производительность: поиск <1 сек, загрузка документа <3 сек
* ✅ Интеграционные тесты проходят + добавлены тесты multi-tenancy

---

## 1) Архитектура данных (логическая модель)

### 1.1 Основные сущности (приоритизированные)

**ФАЗА 1 (КРИТИЧНАЯ — обязательно в первой версии):**

* **users** — пользователи системы (email, password_hash, role, created_at)
* **sessions** — JWT-токены, активные сессии (user_id, token_hash, expires_at, ip)
* **documents** — загруженные файлы (blob, метаданные, owner_id → users)
* **chunks** — чанки текста для RAG с pgvector embeddings (document_id, owner_id, embedding)
* **ai_conversations** — диалоги с AI (user_id, title, created_at, updated_at)
* **ai_messages** — сообщения в диалогах (conversation_id, role [user/assistant/system], content, tokens, cost)
* **search_history** — история поисковых запросов (user_id, query_text, filters, results_count, created_at)
* **api_keys** — ключи провайдеров (user_id, provider, key_ciphertext, is_shared, created_at)
* **user_models** — модели пользователя (user_id, model_id, display_name, pricing, is_active)
* **app_logs** — системные логи (level, user_id, component, message, context_json, created_at)
* **job_queue** — очередь задач (type, user_id, payload, status, priority, created_at)

**ФАЗА 2 (расширение функционала):**

* **document_shares** — расшарка документов между пользователями (many-to-many)
* **teams** — команды/организации (многопользовательские workspace)
* **team_members** — связь users↔teams с ролями
* **token_usage** — детальная статистика по токенам (user_id, model, prompt_tokens, cost_usd, created_at)
* **app_config** — глобальные настройки (admin-only: key, value, type, scope)

**УДАЛЕНО (избыточность):**
* ~~document_versions~~ — не нужно, достаточно updated_at + новый document_id при изменении
* ~~pages~~ — избыточно, информация о страницах в chunks.metadata
* ~~extractions~~ — преждевременно, нет функционала парсинга таблиц
* ~~rag_runs~~ — заменено на job_queue
* ~~search_queries/search_hits~~ — объединено в search_history с JSON результатов
* ~~ai_requests/ai_responses~~ — объединено в ai_conversations/ai_messages
* ~~http_requests~~ — избыточно для первой фазы, логи в app_logs достаточно
* ~~feature_flags~~ — преждевременная оптимизация
* ~~org_checks~~ — специфика тендеров, не относится к RAG

> **Примечание:** pgvector обязателен для `chunks.embedding` (vector(1536) для OpenAI ada-002)

### 1.2 Поля (без DDL, как спецификация)

**api_providers**

* `id`, `name` (openai, deepseek, perplexity …), `base_url?`, `meta jsonb`, `created_at`

**api_keys**

* `id`, `provider_id fk`, `display_name`, `key_ciphertext` (см. шифрование ниже),
* `is_primary bool`, `status enum('not_validated','ok','invalid','limited')`,
* `available_models jsonb`, `added_at`, `validated_at?`, `last_error?`

**documents**

* `id`, `original_filename`, `content_type`, `size_bytes`, `sha256`,
* `blob bytea` (исходный файл),
* `source_label` (e.g. “uploaded”, “downloaded_from_kontur”),
* `uploaded_by user_id?`, `uploaded_at`, `tags text[]`, `status enum('new','parsed','indexed','error')`,
* индексы по (`sha256` уникальный), (`uploaded_at`), (`status`)

**document_versions**

* `id`, `document_id fk`, `version int`, `blob bytea?` (если версии физически храним),
* `change_reason`, `created_at`

**pages**

* `id`, `document_id fk`, `page_num`, `text text`, `text_len`, `lang`, `has_ocr bool`, `created_at`
* ИНДЕКС: (`document_id`,`page_num`), `gin(text)` (опционально)

**extractions**

* `id`, `document_id fk`, `kind enum('metadata','tables','entities','requirements','contacts',...)`,
* `payload jsonb`, `created_at`

**chunks**

* `id`, `document_id fk`, `version int`, `chunk_idx`, `text text`, `text_sha256`,
* `tokens int`, `embedding vector(1536|3072)`, `created_at`
* ИНДЕКС: ivfflat по `embedding` (cosine_ops), (`document_id`,`version`,`chunk_idx`), `hash(text_sha256)`

**rag_runs**

* `id`, `trigger enum('upload','reindex','manual')`, `status enum('pending','running','done','error')`,
* `stats jsonb` (время, кол-во страниц/чанков), `started_at`, `finished_at?`,
* связи `rag_run_documents` (m:n: какие документы обработаны)

**search_queries**

* `id`, `query_text`, `mode enum('keyword','semantic','hybrid')`,
* `params jsonb` (recency/context_size/filters), `user_id?`, `created_at`

**search_hits**

* `id`, `query_id fk`, `document_id fk`, `chunk_id? fk`,
* `score float`, `position int`, `snippet text`, `created_at`

**ai_requests**

* `id`, `provider_id fk`, `model`, `prompt text`, `attachments jsonb`,
* `search_enabled bool`, `search_params jsonb`,
* `created_at`, `request_ms`, `prompt_tokens`, `completion_tokens`

**ai_responses**

* `id`, `request_id fk`, `status enum('ok','error')`, `output text`, `raw jsonb`,
* `completion_tokens`, `cost_usd`, `created_at`

**http_requests**

* `id`, `method`, `path`, `status`, `duration_ms`, `ip`, `user_agent`, `created_at`, `meta jsonb`

**app_logs**

* `id`, `level enum('DEBUG','INFO','WARN','ERROR')`, `component`, `event`, `message`, `context jsonb`, `created_at`

**token_usage**

* `id`, `provider_id fk`, `model`, `prompt_tokens`, `completion_tokens`, `rate_usd_per_million_in/out`, `cost_usd`, `exchange_rate`, `cost_rub`, `created_at`

**app_config**

* `key pk`, `value text`, `type enum('str','int','bool','json','secret')`, `scope enum('global','ui','rag','ocr','pricing')`, `updated_at`

**feature_flags**

* `flag pk`, `enabled bool`, `updated_at`, `note`

**job_queue**

* `id`, `type enum('index','ocr','embed','cleanup')`, `payload jsonb`,
* `status enum('queued','running','done','error')`,
* `priority int`, `locked_by?`, `locked_at?`, `created_at`, `updated_at`

**job_events**

* `id`, `job_id fk`, `kind enum('log','retry','progress')`, `message`, `meta jsonb`, `created_at`

**org_checks** (на перспективу)

* `id`, `org_inn`, `source enum('egrul','pb','fedresurs','kad','fssp','rnp')`,
* `status enum('ok','warning','bad','error')`, `summary text`, `url`, `raw jsonb`, `checked_at`

---

## 2) Стратегия хранения данных

### 2.1 Документы (гибридный подход по размеру)

**Файлы < 10 МБ:** `documents.blob` (bytea)
- Быстрый доступ
- Включаются в бэкап БД
- Оптимально для ≥90% документов

**Файлы 10-50 МБ:** `documents.blob` (bytea) с предупреждением
- Работает, но замедляет бэкапы
- Рекомендация пользователю: разбить или сжать

**Файлы > 50 МБ:** `documents.storage_url` (локальное FS или S3/MinIO)
- `blob` = NULL
- `storage_url` = путь к файлу (например, `/var/app/large_files/{user_id}/{sha256}`)
- В фазе 1: локальное FS (проще)
- В фазе 2: опциональная интеграция S3

**Дедупликация:** По `sha256` в рамках пользователя. Если один файл загружен дважды — один `blob`, две записи в `documents`.

### 2.2 Логи

**Только в БД** (`app_logs`):
- Файловые логи (`logs/app.log`) УДАЛЯЮТСЯ
- В dev-режиме: опциональный `StreamHandler` в консоль (не файл)
- Партиционирование по месяцам (фаза 2)
- Автоочистка записей старше 90 дней (через pg_cron или скрипт)

### 2.3 Ретенция (политики хранения)

| Таблица | Период | Действие |
|---------|--------|----------|
| app_logs | 90 дней | DELETE или перенос в архив |
| sessions | 30 дней | DELETE истёкших |
| search_history | 1 год | Опционально архивировать |
| ai_messages | Бессрочно | До удаления conversation пользователем |
| documents | Бессрочно | До удаления пользователем |

**Реализация:** Еженощный cronjob или `pg_cron` расширение.

---

## 3) Безопасность и шифрование

### 3.1 Аутентификация пользователей

**Пароли:**
- Хеширование: `bcrypt` с cost=12
- Хранение: `users.password_hash`
- Валидация: минимум 8 символов, обязательны буквы + цифры

**JWT токены:**
- Алгоритм: HS256 (симметричный) или RS256 (асимметричный, фаза 2)
- Payload: `{user_id, email, role, exp, iat}`
- TTL: 24 часа (configurable)
- Refresh токены: опционально в фазе 2
- Хранение хеша в `sessions` для отзыва (logout, ban)

**Авторизация:**
- Middleware проверяет JWT → извлекает `user_id`
- Все запросы фильтруются по `user_id` (row-level security)
- Роли: `user` (обычный), `admin` (полный доступ)

### 3.2 Шифрование API-ключей

**Алгоритм:** Fernet (AES-128-CBC + HMAC-SHA256)

**Ключ шифрования:**
```bash
# Генерация один раз
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
```
- Хранение: ENV переменная `FERNET_ENCRYPTION_KEY`
- Ротация: Не поддерживается (требует пересохранение всех ключей)
- Безопасность: Ключ НЕ в git, НЕ в логах, НЕ в UI

**Операции:**
```python
from cryptography.fernet import Fernet

# Шифрование при сохранении
key = os.getenv('FERNET_ENCRYPTION_KEY').encode()
cipher = Fernet(key)
ciphertext = cipher.encrypt(plaintext_api_key.encode()).decode()

# Расшифровка при использовании
plaintext = cipher.decrypt(ciphertext.encode()).decode()
```

**UI маскирование:**
- Показываем только: `sk-proj-...xyz` (первые 12 + последние 3 символа)
- Полный ключ отображается ОДИН раз сразу после добавления
- После — только маска

### 3.3 Защита от атак

**SQL Injection:** SQLAlchemy ORM + parameterized queries
**XSS:** Sanitization на фронтенде (DOMPurify) + CSP headers
**CSRF:** SameSite cookies + CSRF tokens для форм
**Rate Limiting:** 
- Логин: 5 попыток / 15 минут / IP
- API: 100 запросов / минута / пользователь
- Реализация: Flask-Limiter + Redis (опц.) или in-memory counter

**Валидация файлов:**
- Расширение из whitelist (pdf, docx, txt, xlsx)
- Проверка MIME-type через `python-magic`
- Максимальный размер: 100 МБ (configurable)
- Сканирование имени файла: запрет `..`, абсолютных путей

### 3.4 Fail-Fast принцип

При отсутствии `FERNET_ENCRYPTION_KEY` или `DATABASE_URL` — приложение НЕ СТАРТУЕТ с понятной ошибкой:
```python
if not os.getenv('FERNET_ENCRYPTION_KEY'):
    raise RuntimeError("CRITICAL: FERNET_ENCRYPTION_KEY не установлен. Невозможно расшифровать API-ключи.")
```

---

## 4) Инструменты и технологии

### 4.1 ORM и миграции

**SQLAlchemy 2.0+** (обязательно):
- Декларативные модели через `DeclarativeBase`
- Асинхронные сессии НЕ НУЖНЫ (Flask sync)
- Session-per-request pattern

**Alembic** (обязательно):
- Автогенерация миграций: `alembic revision --autogenerate -m "message"`
- Первая миграция создаёт все таблицы + расширения (`CREATE EXTENSION IF NOT EXISTS vector`)
- Rollback стратегия: тестируем `downgrade` перед продом

**Структура:**
```
webapp/
  db/
    __init__.py
    base.py          # DeclarativeBase, engine, sessionmaker
    models.py        # Все SQLAlchemy модели
    repositories/
      users.py       # CRUD для users
      documents.py   # CRUD для documents
      ai.py          # CRUD для conversations/messages
      ...
alembic/
  versions/
    001_initial_schema.py
    002_add_search_history.py
    ...
  env.py
  alembic.ini
```

### 4.2 Удаление старого кода

**УДАЛИТЬ:**
- `webapp/models/rag_models.py` (psycopg2) → заменить на SQLAlchemy
- `utils/api_keys_manager_multiple.py` → перенести логику в `repositories/api_keys.py`
- `utils/token_tracker.py` → перенести в `services/token_service.py` с БД
- `services/state.py` (fcntl-локи) → заменить на транзакции БД
- Все прямые импорты `psycopg2` в бизнес-логике

**ПЕРЕПИСАТЬ:**
- `services/indexing.py` → использовать `DocumentsRepo`, `ChunksRepo`
- `services/rag_service.py` → убрать проверку `db_available`, всегда работать с БД
- `routes/files.py` → читать/писать blob из БД, не из FS

### 4.3 Транзакции

**Уровень изоляции:** `READ COMMITTED` (default PostgreSQL)

**Очередь задач:**
```python
# Конкурентное потребление
with session.begin():
    job = session.execute(
        select(JobQueue)
        .where(JobQueue.status == 'queued')
        .order_by(JobQueue.priority, JobQueue.created_at)
        .limit(1)
        .with_for_update(skip_locked=True)
    ).scalar_one_or_none()
    
    if job:
        job.status = 'running'
        job.locked_by = worker_id
        job.locked_at = datetime.utcnow()
```

**Advisory locks (опционально для критичных операций):**
```python
session.execute(text("SELECT pg_advisory_lock(:lock_id)"), {"lock_id": document_id})
try:
    # critical section
finally:
    session.execute(text("SELECT pg_advisory_unlock(:lock_id)"), {"lock_id": document_id})
```

---

## 5) Миграция существующих данных из файлов в БД

### 5.1 Текущее состояние (что мигрировать)

| Источник | Назначение | Критичность |
|----------|------------|-------------|
| `uploads/**/*` | `documents.blob` + дедупликация | ✅ КРИТИЧНО |
| `index/models.json` | `user_models` (для default user) | ✅ КРИТИЧНО |
| `index/api_keys.json` | `api_keys` (с шифрованием) | ✅ КРИТИЧНО |
| `index/token_usage.json` | Не мигрируем (фаза 2) | ⚠️ Опционально |
| `logs/app.log` | Не мигрируем (старые логи) | ❌ Пропускаем |
| `index/_search_index.txt` | Не мигрируем (пересоздаём) | ❌ Регенерация |

### 5.2 Скрипт миграции данных

**Файл:** `scripts/migrate_files_to_db.py`

**Алгоритм:**

1. **Создать default пользователя** (если система была однопользовательской):
   ```python
   default_user = User(
       email='admin@localhost',
       password_hash=bcrypt.hashpw('changeme'.encode(), bcrypt.gensalt()),
       full_name='System Admin',
       role='admin'
   )
   ```

2. **Мигрировать документы из `uploads/`**:
   ```python
   for file_path in glob('uploads/**/*', recursive=True):
       if os.path.isfile(file_path):
           # Читаем файл
           with open(file_path, 'rb') as f:
               content = f.read()
           
           # Вычисляем хеш
           sha256 = hashlib.sha256(content).hexdigest()
           
           # Проверяем дедупликацию
           existing = session.query(Document).filter_by(
               user_id=default_user.id,
               sha256=sha256
           ).first()
           
           if existing:
               print(f"SKIP (duplicate): {file_path}")
               continue
           
           # Создаём запись
           doc = Document(
               user_id=default_user.id,
               original_filename=os.path.basename(file_path),
               content_type=mimetypes.guess_type(file_path)[0],
               size_bytes=len(content),
               sha256=sha256,
               blob=content if len(content) < 10_000_000 else None,
               storage_url=file_path if len(content) >= 10_000_000 else None,
               status='uploaded',
               uploaded_at=datetime.fromtimestamp(os.path.getmtime(file_path))
           )
           session.add(doc)
           print(f"MIGRATED: {file_path} → document_id={doc.id}")
   ```

3. **Мигрировать API ключи из `index/api_keys.json`**:
   ```python
   with open('index/api_keys.json', 'r') as f:
       keys_data = json.load(f)
   
   cipher = Fernet(os.getenv('FERNET_ENCRYPTION_KEY').encode())
   
   for provider, keys_list in keys_data.items():
       for key_info in keys_list:
           plaintext_key = key_info['key']
           ciphertext = cipher.encrypt(plaintext_key.encode()).decode()
           
           api_key = APIKey(
               user_id=default_user.id,
               provider=provider,
               display_name=key_info.get('name', f'{provider} key'),
               key_ciphertext=ciphertext,
               status='not_validated',
               created_at=datetime.fromisoformat(key_info.get('added_at', datetime.now().isoformat()))
           )
           session.add(api_key)
           print(f"MIGRATED API KEY: {provider} → {api_key.display_name}")
   ```

4. **Мигрировать модели из `index/models.json`**:
   ```python
   with open('index/models.json', 'r') as f:
       models_data = json.load(f)
   
   for model_cfg in models_data.get('models', []):
       user_model = UserModel(
           user_id=default_user.id,
           model_id=model_cfg['model_id'],
           display_name=model_cfg.get('display_name', model_cfg['model_id']),
           provider=model_cfg.get('provider', 'openai'),
           context_window=model_cfg.get('context_window_tokens', 128000),
           supports_search=model_cfg.get('supports_search', False),
           pricing={
               'input_per_1m': model_cfg.get('price_per_million_input_tokens', 0),
               'output_per_1m': model_cfg.get('price_per_million_output_tokens', 0)
           },
           timeout_seconds=model_cfg.get('timeout', 30),
           is_active=True,
           is_default=(model_cfg['model_id'] == models_data.get('default_model'))
       )
       session.add(user_model)
   ```

5. **Коммит и валидация**:
   ```python
   session.commit()
   print(f"\n✅ Миграция завершена:")
   print(f"   - Документов: {session.query(Document).count()}")
   print(f"   - API ключей: {session.query(APIKey).count()}")
   print(f"   - Моделей: {session.query(UserModel).count()}")
   ```

### 5.3 Переиндексация документов

После миграции файлов нужно создать chunks и embeddings:

```python
# Для каждого документа создаём задачу индексации
for doc in session.query(Document).filter_by(status='uploaded').all():
    job = JobQueue(
        type='index_document',
        user_id=doc.user_id,
        payload={'document_id': doc.id},
        status='queued',
        priority=5
    )
    session.add(job)
session.commit()

print(f"✅ Создано {session.query(JobQueue).count()} задач индексации")
```

Воркер обработает очередь и создаст `chunks` с `embeddings`.

### 5.4 Удаление файлов после успешной миграции

**ВНИМАНИЕ:** Удаляем только после 100% подтверждения успеха миграции!

```bash
# Бэкап перед удалением
tar -czf backup_uploads_$(date +%Y%m%d).tar.gz uploads/ index/ logs/

# Удаление (ОСТОРОЖНО!)
rm -rf uploads/
rm -rf index/*.json index/*.txt
rm -rf logs/*.log
```

Оставляем только:
- `index/` (пустая папка, на случай legacy кода)
- `logs/` (пустая, для совместимости)

### 5.5 Rollback план

Если миграция пошла не так:

1. Останавливаем приложение
2. Восстанавливаем бэкап: `tar -xzf backup_uploads_*.tar.gz`
3. Откатываем Alembic: `alembic downgrade -1`
4. Очищаем БД: `DROP DATABASE zakupki_web; CREATE DATABASE zakupki_web;`
5. Возвращаемся к файловой версии кода (ветка `Relise001`)

---

## 6) Многопользовательский доступ (Multi-tenancy)

### 6.1 Принцип изоляции данных

**Row-Level Security через user_id:**
- Все таблицы с пользовательскими данными имеют `user_id`
- Каждый запрос автоматически фильтруется: `WHERE user_id = {current_user.id}`
- Middleware извлекает `user_id` из JWT и устанавливает в контекст запроса

**Реализация в репозиториях:**
```python
class DocumentsRepository:
    def get_user_documents(self, user_id: int) -> List[Document]:
        return session.query(Document).filter_by(user_id=user_id).all()
    
    def get_document_by_id(self, document_id: int, user_id: int) -> Document:
        doc = session.query(Document).filter_by(
            id=document_id,
            user_id=user_id  # КРИТИЧНО: проверка владельца
        ).first()
        if not doc:
            raise PermissionDenied("Document not found or access denied")
        return doc
```

### 6.2 Аутентификация (новые эндпоинты)

**POST `/auth/register`**
```json
{
  "email": "user@example.com",
  "password": "SecurePass123",
  "full_name": "Иван Иванов"
}
```
Ответ: `201 Created`, `{user_id, email, message: "Регистрация успешна"}`

**POST `/auth/login`**
```json
{
  "email": "user@example.com",
  "password": "SecurePass123"
}
```
Ответ: `200 OK`, `{token: "jwt_token_here", user: {id, email, full_name, role}}`

**POST `/auth/logout`**
- Удаляет запись из `sessions` по `token_hash`

**GET `/auth/me`**
- Возвращает профиль текущего пользователя (из JWT)

### 6.3 Авторизация (middleware)

**Файл:** `webapp/middleware/auth.py`

```python
from flask import request, g
import jwt

def auth_middleware():
    """Извлекает user_id из JWT и устанавливает в g.current_user"""
    token = request.headers.get('Authorization', '').replace('Bearer ', '')
    
    if not token:
        return jsonify({'error': 'Unauthorized'}), 401
    
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=['HS256'])
        user_id = payload['user_id']
        
        # Проверка сессии в БД (опционально, для revoke)
        session_exists = db.session.query(Session).filter_by(
            user_id=user_id,
            token_hash=hashlib.sha256(token.encode()).hexdigest()
        ).first()
        
        if not session_exists or session_exists.expires_at < datetime.utcnow():
            return jsonify({'error': 'Token expired'}), 401
        
        g.current_user_id = user_id
        g.current_user = db.session.query(User).get(user_id)
        
    except jwt.ExpiredSignatureError:
        return jsonify({'error': 'Token expired'}), 401
    except jwt.InvalidTokenError:
        return jsonify({'error': 'Invalid token'}), 401
```

**Защита роутов:**
```python
@app.before_request
def require_auth():
    public_routes = ['/auth/login', '/auth/register', '/health']
    if request.path not in public_routes:
        result = auth_middleware()
        if result:  # Если вернулась ошибка
            return result
```

### 6.4 UI изменения

**Новые страницы:**
- `/login` — форма входа
- `/register` — регистрация
- `/profile` — профиль пользователя (смена пароля, email)
- `/history` — история запросов к AI (`ai_conversations`)

**Изменения в существующих:**
- Хедер: добавить кнопку "Выйти" + отображение `user.full_name`
- Боковое меню: добавить "История запросов", "Профиль"
- Все запросы к API: добавить хедер `Authorization: Bearer {token}`

**LocalStorage JWT:**
```javascript
// При логине
localStorage.setItem('auth_token', response.token);

// При каждом запросе
fetch('/api/documents', {
    headers: {
        'Authorization': `Bearer ${localStorage.getItem('auth_token')}`
    }
});
```

### 6.5 Расшаривание документов (Фаза 2)

Таблица `document_shares`:
```sql
CREATE TABLE document_shares (
    id SERIAL PRIMARY KEY,
    document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
    shared_by_user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
    shared_with_user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
    permission VARCHAR(20) DEFAULT 'read',  -- read, write
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(document_id, shared_with_user_id)
);
```

**Логика доступа (расширенная):**
```python
def can_access_document(user_id: int, document_id: int) -> bool:
    # Проверка: владелец ИЛИ есть share
    doc = session.query(Document).filter_by(id=document_id).first()
    if doc.user_id == user_id:
        return True
    
    share = session.query(DocumentShare).filter_by(
        document_id=document_id,
        shared_with_user_id=user_id
    ).first()
    return share is not None
```

---

## 7) Логирование и история работы

### 7.1 Системные логи (app_logs)

**Замена файлового логгера:**
```python
# webapp/utils/db_logger.py
import logging
from webapp.db.repositories.logs import LogsRepository

class DatabaseHandler(logging.Handler):
    def emit(self, record):
        try:
            log_repo = LogsRepository()
            log_repo.create_log(
                level=record.levelname,
                user_id=getattr(g, 'current_user_id', None),
                component=record.name,
                event=record.funcName,
                message=record.getMessage(),
                context={
                    'trace_id': getattr(g, 'trace_id', None),
                    'filename': record.filename,
                    'lineno': record.lineno,
                    'exc_info': self.format(record) if record.exc_info else None
                }
            )
        except Exception:
            # Fallback to stderr if DB fails
            self.handleError(record)
```

**Настройка в app.py:**
```python
# Удаляем файловый handler
for handler in app.logger.handlers[:]:
    app.logger.removeHandler(handler)

# Добавляем DB handler
db_handler = DatabaseHandler()
db_handler.setLevel(logging.INFO)
app.logger.addHandler(db_handler)

# В dev: дополнительно консоль
if app.debug:
    console_handler = logging.StreamHandler()
    app.logger.addHandler(console_handler)
```

### 7.2 История запросов к AI (ai_conversations)

**Создание диалога:**
```python
@app.route('/ai/chat', methods=['POST'])
@require_auth
def create_chat():
    data = request.json
    conv = AIConversation(
        user_id=g.current_user_id,
        title=data.get('title', 'Новый диалог'),
        model=data.get('model', 'gpt-4o-mini'),
        system_prompt=data.get('system_prompt'),
        document_ids=data.get('document_ids', [])
    )
    db.session.add(conv)
    db.session.commit()
    return jsonify({'conversation_id': conv.id}), 201
```

**Отправка сообщения:**
```python
@app.route('/ai/chat/<int:conv_id>/message', methods=['POST'])
@require_auth
def send_message(conv_id):
    conv = AIConversation.query.filter_by(
        id=conv_id,
        user_id=g.current_user_id  # Проверка владельца
    ).first_or_404()
    
    user_message = AIMessage(
        conversation_id=conv.id,
        role='user',
        content=request.json['message']
    )
    db.session.add(user_message)
    
    # Вызов AI
    response_text, tokens, cost = call_ai_model(
        model=conv.model,
        messages=conv.get_all_messages(),
        context_docs=conv.document_ids
    )
    
    assistant_message = AIMessage(
        conversation_id=conv.id,
        role='assistant',
        content=response_text,
        prompt_tokens=tokens['prompt'],
        completion_tokens=tokens['completion'],
        cost_usd=cost,
        model=conv.model
    )
    db.session.add(assistant_message)
    db.session.commit()
    
    return jsonify({
        'message_id': assistant_message.id,
        'content': response_text,
        'tokens': tokens,
        'cost': cost
    })
```

**Получение истории:**
```python
@app.route('/ai/chat/<int:conv_id>', methods=['GET'])
@require_auth
def get_conversation(conv_id):
    conv = AIConversation.query.filter_by(
        id=conv_id,
        user_id=g.current_user_id
    ).first_or_404()
    
    messages = AIMessage.query.filter_by(
        conversation_id=conv.id
    ).order_by(AIMessage.created_at).all()
    
    return jsonify({
        'conversation': conv.to_dict(),
        'messages': [msg.to_dict() for msg in messages],
        'total_cost': sum(msg.cost_usd or 0 for msg in messages)
    })
```

### 7.3 История поиска (search_history)

**Сохранение поиска:**
```python
@app.route('/search', methods=['POST'])
@require_auth
def search_documents():
    query_text = request.json['query']
    search_mode = request.json.get('mode', 'semantic')
    filters = request.json.get('filters', {})
    
    start_time = time.time()
    
    # Выполняем поиск
    results = perform_search(
        user_id=g.current_user_id,
        query=query_text,
        mode=search_mode,
        filters=filters
    )
    
    execution_time_ms = int((time.time() - start_time) * 1000)
    
    # Сохраняем в историю
    search_record = SearchHistory(
        user_id=g.current_user_id,
        query_text=query_text,
        search_mode=search_mode,
        filters=filters,
        results_count=len(results),
        results=[{
            'document_id': r['document_id'],
            'score': r['score'],
            'snippet': r['snippet'][:200]
        } for r in results[:10]],  # Топ-10
        execution_time_ms=execution_time_ms
    )
    db.session.add(search_record)
    db.session.commit()
    
    return jsonify({
        'results': results,
        'search_id': search_record.id,
        'execution_time_ms': execution_time_ms
    })
```

**Получение истории поиска:**
```python
@app.route('/search/history', methods=['GET'])
@require_auth
def get_search_history():
    limit = request.args.get('limit', 50, type=int)
    
    history = SearchHistory.query.filter_by(
        user_id=g.current_user_id
    ).order_by(SearchHistory.created_at.desc()).limit(limit).all()
    
    return jsonify({
        'history': [h.to_dict() for h in history]
    })
```

---

## 8) Конфигурация приложения

* Добавить сервис `ConfigService`:

  * Источник значений: ENV → `app_config` → дефолт.
  * Ключевые настройки: лимиты размеров, OCR-таймауты, модель эмбеддингов, pgvector-параметры, включение/выключение поиска у внешних провайдеров и т. п.
* Перенести из `webapp/config.py` параметры, которые «меняются в рантайме», в `app_config` (UI-страница «Настройки»).

---

## 9) Очереди и конкурентность

* `job_queue` + воркер на той же машине/процессе:

  * `LOCK … SKIP LOCKED`, поле `locked_by`, `locked_at`.
  * Ретраи (экспоненциальные) и лимит попыток.
  * События/логирование в `job_events`.
* Заменить `fcntl`-локи (FilesState) на:

  * `pg_advisory_lock(document_id)` — для операций над документом,
  * либо селекты с `FOR UPDATE`.

---

## 10) Производительность и эксплуатация

* Индексы:

  * `ivfflat` для `chunks.embedding` (lists настраиваемо, по умолчанию 100).
  * B-tree на FK/датах/статусах; GIN на `pages.text` (если используем FTS).
* Партиционирование (опция, этап-2):

  * `app_logs`, `http_requests`, `token_usage` по дате (месяц/неделя).
* Вакуум/автоанализ — проверить параметры БД (документировать).
* Лимиты:

  * Макс. размер загружаемого файла — в конфиг.
  * Ограничение параллельных индексаций — в `app_config` (`max_workers`).

---

## 11) Безопасность

* Валидация расширений (сохранить существующий список), **но** доверять `content_type` из анализа файла, а не из запроса.
* Маскирование ключей в UI.
* Санитизация имён при скачивании (Content-Disposition).
* Поле `documents.sha256` — запрет дубликатов.
* Роли и учётные записи в БД:

  * `app_user` (R/W ограниченный), `app_readonly` (только SELECT), `app_migration` (DDL).
* Защита от DoS: лимитировать размер запроса/число параллельных задач.

---

## 8) Упрощение и устранение дублирования кода

### 8.1 Новая архитектура слоёв

```
webapp/
  db/
    base.py                # DeclarativeBase, engine, create_session
    models.py              # Все SQLAlchemy модели (User, Document, Chunk, etc.)
    repositories/
      base.py              # BaseRepository с CRUD
      users.py             # UsersRepository
      documents.py         # DocumentsRepository  
      chunks.py            # ChunksRepository
      ai.py                # ConversationsRepository, MessagesRepository
      search.py            # SearchHistoryRepository
      api_keys.py          # APIKeysRepository
      jobs.py              # JobQueueRepository
      logs.py              # LogsRepository
  
  services/
    auth.py                # AuthService (login, register, validate_token)
    documents.py           # DocumentService (upload, download, delete, get_user_docs)
    indexing.py            # IndexingService (create_chunks, generate_embeddings)
    search.py              # SearchService (semantic_search, keyword_search, hybrid)
    ai.py                  # AIService (send_message, create_conversation)
    api_keys.py            # APIKeysService (add, validate, decrypt)
  
  routes/
    auth.py                # /auth/login, /auth/register, /auth/logout
    documents.py           # /documents/upload, /documents/<id>, /documents/list
    search.py              # /search, /search/history
    ai.py                  # /ai/chat, /ai/chat/<id>/message
    api_keys.py            # /api_keys/add, /api_keys/list, /api_keys/validate
  
  middleware/
    auth.py                # JWT validation, g.current_user setup
    logging.py             # Request/response logging to app_logs
  
  utils/
    crypto.py              # Fernet encryption/decryption
    validators.py          # File validation, email validation
    pagination.py          # Pagination helper
```

### 8.2 Удаление дублирующего кода

**УДАЛИТЬ ПОЛНОСТЬЮ:**
```
webapp/models/rag_models.py          → Заменён на db/models.py (SQLAlchemy)
utils/api_keys_manager_multiple.py   → Логика в services/api_keys.py
utils/token_tracker.py               → Логика в services/ai.py (подсчёт стоимости)
services/state.py                    → Не нужен (транзакции БД вместо fcntl)
static/js/script.js.bak              → Бэкап (не используется)
test_messages.html                   → Тестовый файл
restart_server.py                    → Не нужен (используем systemd/supervisor)
nohup.out                            → Лог-файл (удалён)
.server.pid                          → PID-файл (не нужен)
verify_fix.py                        → Временный скрипт
README_restart_server.md             → Устаревшая документация
```

**ОБЪЕДИНИТЬ:**
- `document_processor/` + `services/indexing.py` → **один** `services/indexing.py`
- `services/gpt_analysis.py` + `services/rag_service.py` → **один** `services/ai.py`

**ПЕРЕПИСАТЬ:**
- `routes/files.py` → `routes/documents.py` (работа с БД, не с FS)
- `routes/search.py` → использовать `SearchService` вместо прямых файлов
- `routes/ai_rag.py` → разбить на `routes/ai.py` + `routes/api_keys.py`

### 8.3 Единый LLM-клиент

**Файл:** `webapp/services/llm_client.py`

```python
class LLMClient:
    """Единый клиент для всех LLM провайдеров с логированием"""
    
    def __init__(self, user_id: int):
        self.user_id = user_id
        self.api_keys_service = APIKeysService()
    
    def call(self, model: str, messages: List[dict], **kwargs) -> dict:
        """Вызов модели с автоматическим логированием"""
        
        # Получаем провайдер модели
        provider = self._get_provider_for_model(model)
        
        # Получаем API ключ пользователя
        api_key = self.api_keys_service.get_key_for_provider(
            user_id=self.user_id,
            provider=provider
        )
        
        # Создаём клиент провайдера
        client = self._create_client(provider, api_key)
        
        # Вызов API
        start_time = time.time()
        try:
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                **kwargs
            )
            
            duration_ms = int((time.time() - start_time) * 1000)
            
            # Подсчёт стоимости
            cost = self._calculate_cost(
                model=model,
                prompt_tokens=response.usage.prompt_tokens,
                completion_tokens=response.usage.completion_tokens
            )
            
            return {
                'content': response.choices[0].message.content,
                'prompt_tokens': response.usage.prompt_tokens,
                'completion_tokens': response.usage.completion_tokens,
                'cost_usd': cost,
                'duration_ms': duration_ms,
                'finish_reason': response.choices[0].finish_reason
            }
            
        except Exception as e:
            app.logger.error(f"LLM call failed: {e}", extra={
                'user_id': self.user_id,
                'model': model,
                'provider': provider
            })
            raise
```

### 8.4 Репозитории вместо прямых запросов

**Базовый репозиторий:**
```python
# webapp/db/repositories/base.py
from typing import TypeVar, Generic, Type
from sqlalchemy.orm import Session

T = TypeVar('T')

class BaseRepository(Generic[T]):
    def __init__(self, model: Type[T], session: Session):
        self.model = model
        self.session = session
    
    def get_by_id(self, id: int) -> T:
        return self.session.query(self.model).get(id)
    
    def get_all(self) -> List[T]:
        return self.session.query(self.model).all()
    
    def create(self, **kwargs) -> T:
        instance = self.model(**kwargs)
        self.session.add(instance)
        self.session.commit()
        return instance
    
    def update(self, id: int, **kwargs) -> T:
        instance = self.get_by_id(id)
        for key, value in kwargs.items():
            setattr(instance, key, value)
        self.session.commit()
        return instance
    
    def delete(self, id: int) -> bool:
        instance = self.get_by_id(id)
        if instance:
            self.session.delete(instance)
            self.session.commit()
            return True
        return False
```

**Использование:**
```python
# БЫЛО (дублирование)
with open('index/api_keys.json') as f:
    keys = json.load(f)

# СТАЛО (единый интерфейс)
api_keys_repo = APIKeysRepository(session)
keys = api_keys_repo.get_user_keys(user_id=current_user.id)
```

### 8.5 Миграция файловых операций

| Было (файлы) | Стало (БД + репозиторий) |
|--------------|--------------------------|
| `open('uploads/file.pdf')` | `DocumentsRepo.get_blob(doc_id)` |
| `json.load(open('index/models.json'))` | `UserModelsRepo.get_user_models(user_id)` |
| `with open('logs/app.log', 'a')` | `LogsRepo.create_log(...)` |
| `glob('uploads/**/*')` | `DocumentsRepo.get_user_documents(user_id)` |
| `os.remove('uploads/file')` | `DocumentsRepo.delete(doc_id)` |

---

## 13) Тестирование

**Покрыть:**

* Миграции Alembic: пустая БД → готовая схема.
* Загрузка файлов → `documents`, дедуп по `sha256`, версияция.
* Индексация (воркер) → `pages`/`chunks`/`embedding`.
* Семантический поиск → корректность top-k, скоринг/фильтры.
* Логирование в БД (app_logs, http_requests).
* API-ключи CRUD + валидация/маскирование.
* Token usage: стоимость/курсы из `app_config`.
* Очередь задач: конкурентное потребление, ретраи.
* Регрессия старых эндпоинтов из `tests/test_flask_endpoints.py`, `tests/test_grouped_indexing.py`, и т. п.

**Инструментально:**

* Поднять Postgres в Docker (compose) для CI.
* Фикстуры pytest: `db_session`, `clean_db`, `sample_doc`.

---

## 9) Поэтапный план миграции (критичный путь)

### Этап 0: Подготовка инфраструктуры (1 день)

**Задачи:**
- [ ] Создать PostgreSQL БД (Docker Compose или локальная установка)
- [ ] Сгенерировать `FERNET_ENCRYPTION_KEY` и добавить в `.env`
- [ ] Настроить `DATABASE_URL` в `.env`
- [ ] Установить зависимости: `pip install sqlalchemy alembic psycopg2-binary cryptography bcrypt pyjwt`
- [ ] Проверить системные пакеты: `tesseract`, `unrar` (или `unar`), `pdftoppm` (poppler). При отсутствии — описать graceful degradation в MIGRATION_GUIDE
- [ ] Зафиксировать режим совместимости: в README/MIGRATION_GUIDE описать флаг `USE_DATABASE` (`app_config.use_database`) и сценарии переключения
- [ ] Создать backup существующих данных: `tar -czf backup_$(date +%Y%m%d).tar.gz uploads/ index/ logs/`

**Проверка:**
```bash
psql $DATABASE_URL -c "SELECT version();"  # БД доступна
python -c "from cryptography.fernet import Fernet; Fernet(b'...')"  # Ключ валиден
tesseract --version  # OCR доступен (если отсутствует — фиксируем предупреждение)
unrar  # либо `unar --version`
python - <<'PY'
import shutil
print('poppler (pdftoppm) найден:', bool(shutil.which('pdftoppm')))
PY
```

---

### Этап 1: Схема БД и базовый DAL (2 дня)

**Задачи:**
- [ ] Настроить Alembic (`alembic init alembic`)
- [ ] Создать SQLAlchemy модели в `webapp/db/models.py` (User, Document, Chunk, etc.)
- [ ] Написать первую миграцию: `alembic revision --autogenerate -m "Initial schema"`
- [ ] Применить миграцию: `alembic upgrade head`
- [ ] Создать `BaseRepository` и специализированные репозитории
- [ ] Написать unit-тесты для репозиториев

**Проверка:**
```bash
alembic current  # Показывает текущую версию
psql $DATABASE_URL -c "\dt"  # Список таблиц (users, documents, chunks, etc.)
pytest tests/test_repositories.py  # Тесты проходят
```

---

### Этап 2: Аутентификация и многопользовательский режим (2 дня)

**Задачи:**
- [ ] Создать `AuthService` (register, login, validate_token)
- [ ] Реализовать роуты `/auth/register`, `/auth/login`, `/auth/logout`
- [ ] Добавить `auth_middleware` с проверкой JWT
- [ ] Обновить UI: добавить страницы логина/регистрации
- [ ] Защитить все существующие роуты middleware

**Проверка:**
```bash
curl -X POST http://localhost:8081/auth/register -d '{"email":"test@test.com","password":"pass123"}'
# Ответ: {"user_id": 1, "message": "Success"}

curl -X POST http://localhost:8081/auth/login -d '{"email":"test@test.com","password":"pass123"}'
# Ответ: {"token": "jwt_token_here"}

curl http://localhost:8081/documents -H "Authorization: Bearer <token>"
# Ответ: [] (пустой список документов, но 200 OK)
```

---

### Этап 3: Миграция данных из файлов в БД (1 день)

**Задачи:**
- [ ] Написать скрипт `scripts/migrate_files_to_db.py`
- [ ] Создать default пользователя (admin@localhost)
- [ ] Мигрировать документы из `uploads/` → `documents.blob`
- [ ] Мигрировать API ключи из `index/api_keys.json` → `api_keys` (с шифрованием)
- [ ] Мигрировать модели из `index/models.json` → `user_models`
- [ ] Запустить скрипт: `python scripts/migrate_files_to_db.py`

**Проверка:**
```sql
SELECT COUNT(*) FROM documents;  -- Количество = файлов в uploads/
SELECT COUNT(*) FROM api_keys;   -- Количество = ключей в index/api_keys.json
SELECT COUNT(*) FROM user_models; -- Количество = моделей в models.json
```

---

### Этап 4: Индексация и поиск через БД (3 дня)

**Задачи:**
- [ ] Переписать `services/indexing.py` для работы с БД (ChunksRepo)
- [ ] Реализовать воркер очереди задач (`JobQueueService`)
- [ ] Создать задачи индексации для всех документов
- [ ] Запустить воркер: генерация chunks + embeddings
- [ ] Реализовать `SearchService` (semantic, keyword, hybrid)
- [ ] Обновить роут `/search` для работы с БД

**Проверка:**
```sql
SELECT COUNT(*) FROM chunks;  -- Чанки созданы
SELECT COUNT(*) FROM chunks WHERE embedding IS NOT NULL;  -- Embeddings есть

-- Тест семантического поиска
SELECT id, content, embedding <=> '[0.1, 0.2, ...]'::vector AS distance
FROM chunks
ORDER BY distance
LIMIT 5;
```

---

### Этап 5: История запросов и логирование (2 дня)

**Задачи:**
- [ ] Создать `AIService` с логированием в `ai_conversations`/`ai_messages`
- [ ] Реализовать роуты `/ai/chat`, `/ai/chat/<id>/message`
- [ ] Заменить файловый логгер на `DatabaseHandler` (`app_logs`)
- [ ] Сохранять историю поиска в `search_history`
- [ ] Добавить UI страницу "История запросов"

**Проверка:**
```bash
curl -X POST http://localhost:8081/ai/chat -H "Authorization: Bearer <token>" \
  -d '{"title":"Test","model":"gpt-4o-mini"}'
# Ответ: {"conversation_id": 1}

curl -X POST http://localhost:8081/ai/chat/1/message -H "Authorization: Bearer <token>" \
  -d '{"message":"Hello"}'
# Ответ: {"message_id": 2, "content": "AI response..."}

SELECT COUNT(*) FROM ai_messages;  -- Сообщения сохранены
SELECT COUNT(*) FROM app_logs WHERE level='INFO';  -- Логи пишутся в БД
```

---

### Этап 6: Удаление файлового состояния (1 день)

**Задачи:**
- [ ] Проверить, что всё работает БЕЗ файлов
- [ ] Удалить ссылки на `uploads/`, `index/*.json`, `logs/*.log` из кода
- [ ] Удалить физические файлы/папки (после подтверждения)
- [ ] Удалить устаревшие скрипты (`restart_server.py`, `nohup.out`, etc.)
- [ ] Обновить `.gitignore` (убрать `uploads/`, `index/`, `logs/`)

**Проверка:**
```bash
grep -r "uploads/" webapp/  # Нет результатов
grep -r "index/.*\.json" webapp/  # Нет результатов
ls uploads/ index/ logs/  # Папки пусты или не существуют
```

---

### Этап 7: Тестирование и оптимизация (2 дня)

**Задачи:**
- [ ] Обновить существующие тесты для работы с БД
- [ ] Добавить тесты multi-tenancy (изоляция пользователей)
- [ ] Добавить тесты миграций (up/down)
- [ ] Нагрузочное тестирование: 1000 документов, 100 запросов
- [ ] Оптимизация индексов БД (EXPLAIN ANALYZE)
- [ ] Настройка параметров pgvector (`lists` для IVFFlat)

**Проверка:**
```bash
pytest tests/ -v  # Все тесты проходят
pytest tests/test_multi_tenancy.py  # Изоляция работает

# Нагрузка: 100 запросов за <10 сек
ab -n 100 -c 10 -H "Authorization: Bearer <token>" http://localhost:8081/search
```

---

### Этап 8: Документация и деплой (1 день)

**Задачи:**
- [ ] Обновить README.md (инструкции запуска с БД)
- [ ] Добавить ER-диаграмму (mermaid или draw.io)
- [ ] Написать `docs/MIGRATION_GUIDE.md` (как мигрировать с файлов)
- [ ] Настроить systemd/supervisor для автозапуска
- [ ] Настроить backup БД (cron + pg_dump)
- [ ] Финальная проверка на production-like окружении

**Проверка:**
- [ ] Приложение стартует при перезагрузке сервера
- [ ] Backup создаётся автоматически (проверить cron)
- [ ] README актуален и работает для нового пользователя

---

### Итоговая оценка времени: **14 рабочих дней** (~ 3 недели)

**Критичный путь:**
Этап 0 → Этап 1 → Этап 2 → Этап 3 → Этап 4 → Этап 5 → Этап 6 → Этап 7 → Этап 8

**Риски:**
- Проблемы с pgvector на старой версии PostgreSQL → обновить до 14+
- Долгая генерация embeddings → распараллелить воркеры
- Утрата данных при миграции → бэкапы обязательны на каждом этапе

---

## 15) Нефункциональные требования

* **Надёжность**: все критические операции — в транзакциях, ошибки — с ретраями.
* **Наблюдаемость**: трейс-id в логах, запросах, задачах.
* **Производительность**: индексация 100 документов среднего размера (<10 МБ) ≤ 10 мин при 4 воркерах и доступе к внешнему API эмбеддингов.
* **Резервное копирование**: ежедневные бэкапы БД; чек-лист восстановления.
* **Ретенция**: `app_logs/http_requests` — хранение 90 дней (настраиваемо), далее — архивация/удаление.

---

## 16) Совместимость и изменения в UI

* Поведение UI сохраняется (кнопки, страницы).
* В местах, где раньше был статус индекса/файлов — теперь статусы документов/задач из БД.
* Добавить страницу «Настройки» (чтение/запись `app_config`) и «Логи» (просмотр `app_logs`).

---

## 17) Риски и ограничения

* Увеличение размера БД из-за хранения BLOB: нужна дисциплина по ретенции и дедупликации (sha256).
* Скорость семантического поиска зависит от параметров ivfflat и размера `lists`.
* Внешние лимиты провайдеров эмбеддингов — очередь/троттлинг.

---

## 10) Критерии приёмки (Definition of Done)

### 10.1) Функциональность ✅

- [ ] **Регистрация/Логин**: Пользователь может создать аккаунт (email/password), войти, получить JWT токен
- [ ] **Изоляция данных**: Пользователь A видит только свои документы/запросы, пользователь B — только свои
- [ ] **Загрузка документов**: Файлы сохраняются в БД (`documents.blob`), генерируется hash для дедупликации
- [ ] **Индексация**: Документы автоматически нарезаются на чанки, генерируются embeddings (pgvector)
- [ ] **Поиск**: Keyword + semantic поиск работают, возвращают сниппеты с координатами
- [ ] **История запросов**: Все AI-диалоги сохраняются в `ai_conversations`/`ai_messages`, можно восстановить контекст
- [ ] **API ключи**: Хранятся в БД зашифрованными (Fernet), в UI показываются `***`, доступны только владельцу
- [ ] **Модели пользователя**: Настройки моделей сохраняются per-user, изолированы

### 10.2) Безопасность 🔒

- [ ] **JWT токены**: Генерируются с `HS256`, срок жизни 7 дней, хранятся в `sessions`, можно отозвать
- [ ] **Пароли**: Хешируются bcrypt (cost=12), нигде не логируются в plaintext
- [ ] **Шифрование API ключей**: Используется Fernet, ключ в `.env`, не коммитится
- [ ] **Row-level security**: Все таблицы фильтруются по `user_id`, нет утечек между пользователями
- [ ] **Rate limiting**: Защита от bruteforce login (5 попыток/минуту)
- [ ] **Path traversal**: Проверка `_is_safe_subpath` для всех файловых операций
- [ ] **SQL Injection**: Использование ORM (SQLAlchemy) с параметризованными запросами

### 10.3) Производительность 🚀

- [ ] **Поиск**: <500ms на запрос (keyword) / <2s (semantic) для 10k чанков
- [ ] **Индексация**: <1s на документ (без OCR), <5s (с OCR)
- [ ] **Login**: <300ms (включая bcrypt)
- [ ] **Pgvector**: IVFFlat индекс настроен, `lists` = sqrt(rows), проверка EXPLAIN ANALYZE
- [ ] **Нагрузка**: 100 одновременных запросов без ошибок 5xx

### 10.4) Надёжность 💪

- [ ] **Транзакции**: Все многошаговые операции (индексация, удаление) атомарны
- [ ] **Откат миграций**: `alembic downgrade -1` работает без потери данных
- [ ] **Backup/Restore**: `pg_dump` → `pg_restore` восстанавливает полную БД <3 минут
- [ ] **Graceful degradation**: Отсутствие tesseract/unrar не ломает систему, только логирует warning
- [ ] **Job queue**: Фоновые задачи не блокируют HTTP-ручки, логируют ошибки

### 10.5) Тестирование 🧪

**⚠️ КРИТИЧНО: Передача в ручное тестирование ТОЛЬКО после прохождения всех автотестов!**

- [ ] **Unit-тесты**: Покрытие >70% для `webapp/db/`, `webapp/services/`
- [ ] **Integration тесты**: Полный цикл (register → upload → index → search → logout)
- [ ] **Multi-tenancy тесты**: User A не видит данных User B (проверка изоляции)
- [ ] **Migration тесты**: Upgrade/downgrade миграций работает
- [ ] **Load тесты**: 1000 документов индексируются за <20 минут
- [ ] **Автотесты проходят**: `pytest tests/ -v` без ошибок → только после этого ручное тестирование

### 10.6) Документация 📚

- [ ] **README.md**: Инструкции по запуску с БД (Docker Compose, переменные окружения)
- [ ] **MIGRATION_GUIDE.md**: Пошаговый план миграции с файлов на БД
- [ ] **ER-диаграмма**: Схема БД в формате mermaid или PNG
- [ ] **API документация**: OpenAPI/Swagger спецификация для всех эндпоинтов
- [ ] **Комментарии в коде**: Docstrings для всех публичных классов/методов

### 10.7) Чистота кода 🧹

- [ ] **Удалены файлы**: `rag_models.py`, `init_rag_db.py`, дубли LLM-клиентов (10+ файлов)
- [ ] **Нет файлового состояния**: `uploads/`, `index/*.json`, `logs/*.log` удалены из проекта
- [ ] **Единый стиль**: Black formatter, type hints, PEP8
- [ ] **Нет TODO/FIXME**: Все временные костыли убраны или задокументированы
- [ ] **Unified LLM client**: Один класс `LLMClient` вместо разбросанных вызовов OpenAI/Anthropic

### 10.8) Проверка деплоя 🚢

- [ ] Приложение стартует командой `python app.py` (или `gunicorn app:app`)
- [ ] Systemd/Supervisor настроен, автозапуск после перезагрузки сервера
- [ ] Cron-задача для backup БД выполняется ежедневно
- [ ] Логи пишутся в БД (`app_logs`), доступны через `/admin/logs` (только для admin role)
- [ ] Healthcheck эндпоинт `/health` возвращает 200 OK + статус БД
- [ ] Мониторинг: Prometheus/Grafana (опционально, для продакшена)

---

### Минимальный набор для запуска (MVP):
- Этапы 0-4 (схема, auth, миграция данных, индексация, поиск)
- Критерии: 10.1, 10.2, 10.6 (README)
- **Время: ~8 дней**

### Полная версия (Production-ready):
- Все этапы 0-8
- Все критерии 10.1-10.8
- **Время: ~14 дней**

---

## 11) План проверки реализации (QA Strategy)

Цель: убедиться, что реализованные изменения соответствуют спецификации, безопасны и не ломают текущий функционал.

Последовательность этапов:
- Этап A: Статический контроль качества (линтеры/типы)
- Этап B: Автотесты (юнит, интеграционные, миграции, нагрузочные)
- Этап C: Ручное тестирование по сценариям
- Этап D: Проверка деплоя и отката

Жёсткое правило допуска: к этапу C (ручные проверки) переходим ТОЛЬКО если этап B (все автотесты) зелёный.

Чек-лист (реализация):
- [ ] Код собирается без ошибок линтера/типов (ruff/flake8, mypy — при наличии)
- [ ] Все зависимости указаны в `requirements.txt`, версии зафиксированы
- [ ] Конфиги читаются только из ENV/БД, нет захардкоженных секретов
- [ ] Логи не содержат персональные данные и секреты
- [ ] Миграции Alembic повторяемы на чистой БД
- [ ] Фичи-флаги/настройки управляются через `app_config`

Чек-лист (безопасность):
- [ ] Все защищённые эндпоинты требуют JWT
- [ ] Пароли — только bcrypt hash; API-ключи — только в зашифрованном виде
- [ ] Нет SQL-инъекций (ORM, параметризованные запросы)
- [ ] Проверка безопасных путей `_is_safe_subpath` включена везде, где есть вложения

---

## 12) План проверки автотестированием (CI/CD)

Три слоя автотестов:
1) Unit: сервисы/репозитории в изоляции (mock DB/LLM)
2) Integration: реальные миграции, тестовая БД, HTTP-роуты
3) Performance/Load: индексация/поиск на объёмах, базовые SLA

Правило допуска: ручное тестирование стартует ТОЛЬКО после «зелёного» статуса всех слоёв автотестов.

Чек-лист автотестов:
- [ ] Unit: `tests/services` — AuthService, SearchService, AIService
- [ ] Unit: `tests/db` — репозитории CRUD, транзакции, фильтр по `user_id`
- [ ] Integration: регистрация → логин → загрузка → индексация → поиск → логаут (полный happy-path)
- [ ] Integration: миграции Alembic up/down на чистой БД
- [ ] Integration: multi-tenant изоляция (A не видит B) — минимум 3 кейса
- [ ] Integration: шифрование ключей (Fernet), отображение маской в UI
- [ ] Load: индексация 1000 документов ≤ 20 мин; поиск 100 запросов без 5xx
- [ ] Smoke: healthcheck `/health` отдаёт 200 + статус БД

Метрики прохода:
- [ ] Покрытие unit > 70% для `webapp/db`, `webapp/services`
- [ ] Все тесты `pytest -q` зелёные; падения — блокер для релиза
- [ ] Время CI ≤ 15 минут (без load-тестов)

---

## 13) Ручной план проверки (UAT)

Проводится после успешного прохождения всех автотестов. Фокус — UX, сценарии пользователя и безопасность.

Сценарии (основные):
1) Регистрация/логин/логаут (валид/невалид пароли, rate limiting)
2) Загрузка документов разных форматов (TXT, PDF, DOCX, ZIP/RAR) и размеров
3) Индексация: статус задач, ошибки OCR/RAR — не валят UI
4) Поиск: keyword/semantic, корректные сниппеты, пагинация
5) История запросов: AI-диалоги создаются, подтягивается контекст
6) Управление ключами: добавление/редактирование/удаление, маска `***`
7) Многопользовательский режим: изоляция A/B, запрет доступа по чужим ID
8) Логи и мониторинг: страница логов доступна только администратору
9) Резервные копии: план бэкапа, пробный restore на отдельной БД
10) Деплой/откат: перезапуск службы, проверка, что данные на месте

Чек-лист UAT:
- [ ] Все страницы UI открываются и работают без ошибок в консоли браузера
- [ ] Русская локализация: тексты, ошибки, подсказки корректны
- [ ] Сообщения об ошибках краткие и понятные (без трейсбеков)
- [ ] При отсутствии системных зависимостей (tesseract/unrar) — «мягкая» деградация
- [ ] Удаление/скачивание файлов проверено на traversal (нельзя выйти за `uploads/`)
- [ ] Автологин по истёкшему JWT невозможен; логаут отзывает сессию
- [ ] Производительность UI: страницы открываются < 1 сек на типовом стенде

Принятие:
- [ ] Все пункты чек-листа пройдены
- [ ] Открытые дефекты классифицированы и либо исправлены, либо отнесены в backlog
- [ ] Подтверждение заказчика о готовности к релизу

---

## 14) Разделение спецификации на этапы

Этот инкремент разделён на две части, чтобы снизить риски и ускорить переход на БД.

### Часть 1 — Обязательно при миграции (минимально жизнеспособный релиз)

Цель: перевести систему на PostgreSQL без потери текущего функционала, обеспечить многопользовательский режим и сохранить совместимость с существующими сценариями.

Состав (ссылки на разделы спецификации):
- [ ] Зависимости: добавить в `requirements.txt` SQLAlchemy, Alembic, cryptography, bcrypt, PyJWT, python-dotenv; зафиксировать версии — см. Этап 0
- [ ] Пререквизиты: описать системные пакеты (tesseract, unrar, poppler) и проверки наличия при старте — см. Этап 0
- [ ] База данных и ORM: SQLAlchemy + Alembic; начальная схема (users, sessions, documents, chunks, api_keys, user_models, search_history, app_logs, job_queue) — см. пп. 1.1–1.2, Этап 1
- [ ] Dual-mode конфигурация: флаг `app_config.use_database`, адаптер, генерирующий `_search_index.txt` из БД на переходный период, и обратная запись в БД при legacy-пути — см. рекомендации
- [ ] Аутентификация: AuthService (JWT, bcrypt), middleware, эндпоинты `/auth/*`, роли user/admin — см. Этап 2
- [ ] Ротация секретов (минимум): зафиксировать хранение `FERNET_ENCRYPTION_KEY` и `JWT_SECRET_KEY` с указанием процедуры аварийной смены (два ключа — active/next) — см. п. 3.2
- [ ] Миграция данных: перенос uploads/, index/api_keys.json, index/models.json в БД; валидация checksum, rollback на ошибках — см. Этап 3
- [ ] Индексация и поиск: записи в chunks + embeddings (pgvector), базовый SearchService, сохранение search_history — см. Этап 4–5
- [ ] Логирование: переход на `app_logs` через DatabaseHandler, маскирование секретов в логах — см. Этап 5
- [ ] Тестирование: автотесты (unit + integration + миграции) зелёные, только после этого — ручные проверки — см. п. 10.5, пп. 11–13
- [ ] Документация: обновлённый README и MIGRATION_GUIDE (с описанием dual-mode и rollback) — см. Этап 8

Нефункциональные критерии Часть 1:
- [ ] Поиск keyword < 500мс; semantic < 2с на 10k чанков
- [ ] Индексация без OCR < 1с/док; с OCR < 5с/док (best effort)
- [ ] Изоляция данных (user_id) подтверждена интеграционными тестами
- [ ] Dual-mode покрыт тестами: при `use_database=false` и `true` результат поиска идентичен
- [ ] Резервное копирование БД: pg_dump по расписанию, пробный restore документирован

Результат: система работает на БД, поддерживает нескольких пользователей, хранит документы и ключи в БД, поиск идёт через БД, совместимость с legacy-путём сохранена флагом до переписывания всех экранов/тестов.

---

### Часть 2 — Рекомендуется после завершения Части 1 (в отдельный релиз)

Цель: улучшить UX, расширить аудит и историю, добавить мониторинг и оптимизации производительности.

Состав:
- [ ] Полная история AI-диалогов: ai_conversations/ai_messages с UI страницей, восстановлением контекста и фильтрами — см. Этап 5
- [ ] Политики RLS на уровне БД: включить `ALTER TABLE ... ENABLE ROW LEVEL SECURITY`, добавить `CREATE POLICY ... USING (user_id = current_setting('app.user_id')::int)`; внедрить установку `SET app.user_id` в сессии — расширение п. 1.2
- [ ] Очередь задач: ретраи с экспоненциальным backoff, DLQ, мониторинг состояния воркеров, ручное переотправление задач — см. Этап 4, 8
- [ ] OpenAPI/Swagger: описание всех эндпоинтов + генерация клиента, выкладка на `/docs`
- [ ] Мониторинг/алерты: Prometheus-метрики (`index_queue_depth`, `job_failures_total`, `search_latency_ms`, `db_pool_usage`), алерты (SLA поиска, рост ошибок)
- [ ] UI-улучшения: страница истории запросов, админ-логов, настройки моделей/лимитов
- [ ] Расширенная ротация секретов: хранение keyid/версии, автоматический rollover (active/next), миграция шифрованных записей
- [ ] Политики ретенции: документы > X ГБ и старше Y месяцев — архив/удаление; история AI — 180 дней; searchable chunks — очищать по TTL
- [ ] Оптимизации pgvector: настройка `lists`, возможно партиционирование по `user_id`, батчевые upsert embeddings, поддержка HNSW (если обновится pgvector)
- [ ] Полный отказ от legacy `_search_index.txt`, переписанные тесты на БД, удаление dual-mode флагов и сопутствующего кода

Критерии готовности Части 2:
- [ ] Все UI страницы работают поверх БД без генерации файла индекса
- [ ] Метрики и алерты доступны на дашборде, SLA контролируется
- [ ] OpenAPI опубликован и соответствует реализации; автогенерируемый клиент проходит smoke-тест
- [ ] Legacy режим удалён; тесты переведены на БД полностью; пайплайн CI проверяет только режим БД

Примечание: Часть 2 переносится в отдельный инкремент/релиз после стабилизации Части 1.

---

## 19) Что именно сделать GitHub Copilot’у (по задачам)

1. **Ввести Alembic и SQLAlchemy (ORM)**

   * Создать пакет `webapp/db/…`, перенести модели из `rag_models.py`, расширить до полной схемы (п.1.2).
   * Настроить `DATABASE_URL` из ENV, добавить профили (dev/test/prod).

2. **Сервис конфигурации**

   * `ConfigService` (ENV→`app_config`→дефолт), CRUD для UI.

3. **Документы и индексация**

   * Загрузка → запись в `documents` (bytea, sha256), версияция.
   * Воркер индексации: `pages`→`chunks`→`embedding` (pgvector).
   * Переписать `document_processor`/`services/indexing.py` на репозитории.

4. **Поиск**

   * Роут поиска использует DAL: сохраняет `search_queries`, выдаёт `search_hits`.
   * Реализация гибридного поиска (ключевой/семантический) по параметрам.

5. **Логи/HTTP-аудит**

   * Заменить файловый логгер на DB-handler.
   * Middleware пишет в `http_requests`.

6. **LLM-слой и учёт токенов**

   * Ввести `LLMClient`: централизованный вызов провайдеров, фиксация `ai_requests/ai_responses/token_usage`.

7. **API-ключи**

   * Перенести менеджер ключей на БД + шифрование (Fernet), UI — маскировать.

8. **Очередь задач**

   * `job_queue` + воркер с конкурентным потреблением (`SKIP LOCKED`), ретраями.

9. **Удаление старого**

   * Вырезать файловые состояния/JSON, почистить мёртвые файлы/дубли.

10. **Тесты и доки**

* Обновить/добавить тесты; описать запуск БД и миграций; добавить ER-диаграмму (md/мермайд).

---

## 20) Резюме и ключевые решения

### Что меняется фундаментально:
1. **С файлов на БД**: Всё состояние (документы, настройки, логи, история) переносится в PostgreSQL
2. **Многопользовательский режим**: Обязательная регистрация/логин, изоляция данных по `user_id`
3. **Полная история**: Сохранение всех AI-диалогов и поисковых запросов для каждого пользователя
4. **Безопасность**: JWT-токены, bcrypt-хэши паролей, Fernet-шифрование API ключей

### Что НЕ меняется:
- UI и UX (кроме добавления страниц логина/регистрации/истории)
- Форматы поддерживаемых документов (TXT, PDF, DOCX, XLSX, ZIP, RAR, etc.)
- Логика поиска (keyword + semantic через pgvector)
- Интеграция с LLM провайдерами (OpenAI, Anthropic, etc.)

### Критичные точки внимания:
- ⚠️ **Backup данных** перед началом миграции (обязательно `tar -czf backup.tar.gz uploads/ index/ logs/`)
- ⚠️ **Тестирование изоляции** между пользователями (User A не видит данных User B)
- ⚠️ **Производительность pgvector** (настройка IVFFlat индекса, параметр `lists`)
- ⚠️ **Шифрование** API ключей (не потерять `FERNET_ENCRYPTION_KEY` из `.env`!)
- ⚠️ **Миграции Alembic** (тестировать upgrade/downgrade перед продакшеном)

### Успешная миграция это когда:
- ✅ Приложение работает БЕЗ файлов `uploads/`, `index/*.json`, `logs/*.log`
- ✅ Два пользователя не видят данных друг друга (row-level security работает)
- ✅ История всех запросов сохранена в БД и доступна через UI
- ✅ Откат миграции возможен (`alembic downgrade -1` без потери данных)
- ✅ Backup/restore БД занимает <3 минут (pg_dump + pg_restore)
- ✅ Все тесты проходят (unit + integration + multi-tenancy)

### Архитектурные принципы:
1. **Repository Pattern**: Весь доступ к БД через репозитории (`UserRepository`, `DocumentRepository`, etc.)
2. **Service Layer**: Бизнес-логика в сервисах (`AuthService`, `SearchService`, `AIService`)
3. **Middleware Auth**: Проверка JWT на уровне middleware, запись `request.user`
4. **Transaction Management**: Все многошаговые операции в транзакциях
5. **Graceful Degradation**: Отсутствие опциональных зависимостей (tesseract, unrar) не ломает систему

### Технический стек ПОСЛЕ миграции:
- **БД**: PostgreSQL 14+ с pgvector extension
- **ORM**: SQLAlchemy 2.0+ (async готовность для будущего)
- **Миграции**: Alembic
- **Auth**: JWT (HS256) + bcrypt (cost=12)
- **Encryption**: Fernet (AES-128-CBC + HMAC-SHA256)
- **Search**: Keyword (PostgreSQL FTS) + Semantic (pgvector cosine similarity)
- **Background Jobs**: Job queue table + worker process(es)

### Файлы для удаления (после успешной миграции):
```bash
# Старый код PostgreSQL (psycopg2)
rm rag_models.py init_rag_db.py

# Скрипты перезапуска сервера
rm restart_server.py nohup.out

# Бэкапы/дубли
rm -rf static/js/script.js.bak
rm test_messages.html .server.pid

# Физические данные (после переноса в БД)
rm -rf uploads/ index/*.json logs/*.log
```

### Оценка сложности:
- **Простота реализации**: ⭐⭐⭐⭐ (4/5) — стандартный стек, понятная архитектура
- **Риск при миграции**: ⭐⭐⭐ (3/5) — требуется тщательное тестирование изоляции
- **Поддержка в будущем**: ⭐⭐⭐⭐⭐ (5/5) — стандартный подход, легко расширять
- **Время на реализацию**: **14 рабочих дней** (полная версия) / **8 дней** (MVP)

---

**Дата составления спецификации:** 2025-11-03  
**Версия:** 2.0 (полная переработка после уточнения требований)  
**Статус:** ✅ Готово к реализации (требуется подтверждение заказчика)

---

## 21) Пошаговый чек-лист Часть 1

### Шаг 1. Добавляем зависимости ✅

**Чек-лист для Copilot**
- [x] Обновить `requirements.txt`, добавив `sqlalchemy`, `alembic`, `cryptography`, `bcrypt`, `PyJWT`, `python-dotenv` с зафиксированными версиями.
- [x] Установить зависимости в `.venv` и убедиться, что `pip check` проходит без ошибок.
- [x] Добавить быстрый импортный тест (`tests/test_dependencies_import.py`).

**Чек-лист для ручной проверки**
- [x] Выполнить `pip freeze | grep -E "(SQLAlchemy|alembic|cryptography|bcrypt|PyJWT|python-dotenv)"` и убедиться, что версии совпадают со спецификацией.
- [x] Запустить `python -m pip check` и зафиксировать отсутствие конфликтов.
- [x] Убедиться, что `pytest tests/test_dependencies_import.py -q` завершается успешно.

### Шаг 2. Настраиваем переменные окружения ✅

**Чек-лист для Copilot**
- [x] Создать `.env.sample` с обязательными ключами (`DATABASE_URL`, `FERNET_ENCRYPTION_KEY`, `JWT_SECRET_KEY`).
- [x] Реализовать загрузку настроек через `python-dotenv` и `ConfigService`.
- [x] Добавить fail-fast проверки при отсутствии ключевых переменных.
- [x] Написать тест `tests/test_config_env.py` на сценарии с отсутствием переменных.

**Чек-лист для ручной проверки**
- [x] Скопировать `.env.sample` в `.env` и заполнить значения.
- [x] Запустить `pytest tests/test_config_env.py -q`.
- [x] Запустить приложение без `.env` и убедиться, что оно корректно завершается с понятной ошибкой.

### Шаг 3. Инициализируем Alembic ✅

**Чек-лист для Copilot**
- [x] Выполнить `alembic init alembic` (через автоматизацию) и добавить каталоги в репозиторий.
- [x] Сконфигурировать `alembic.ini` на чтение `DATABASE_URL` из настроек приложения.
- [x] Обновить `alembic/env.py` с использованием `SQLAlchemy` `MetaData` из проекта.

**Чек-лист для ручной проверки**
- [x] Запустить `alembic upgrade head` на чистой БД — команда не должна падать (пока таблиц нет).
- [x] Проверить структуру каталогов `alembic/` и наличие `versions/`.
- [x] Просмотреть `alembic.ini` на отсутствие хардкода URL.

### Шаг 4. Собираем базовый слой SQLAlchemy ✅

**Чек-лист для Copilot**
- [x] Создать `webapp/db/base.py` с `DeclarativeBase`, `engine`, `sessionmaker` и фабрикой сессий.
- [x] Добавить `ScopedSession` для использования в Flask (middleware).
- [x] Написать модульный тест `tests/test_db_session.py` с проверкой открытия/закрытия сессий.

**Чек-лист для ручной проверки**
- [x] Запустить `pytest tests/test_db_session.py -q`.
- [x] Проверить, что `Base.metadata` подтягивается в Alembic.
- [x] Убедиться, что при запросе к БД соединение закрывается после выхода из контекста.

### Шаг 5. Описываем модели данных ✅

**Чек-лист для Copilot**
- [x] Заполнить `webapp/db/models.py` сущностями из раздела 1.1 (users, sessions, documents, chunks, api_keys, user_models, search_history, app_logs, job_queue).
- [x] Добавить `__tablename__`, индексы и связи.
- [x] Создать тесты `tests/test_db_models_schema.py` для проверки наличия ключевых полей и ограничений.

**Чек-лист для ручной проверки**
- [x] Запустить `pytest tests/test_db_models_schema.py -q`.
- [x] Проверить, что модели не вызывают кольцевых импортов.
- [x] Просмотреть docstring'и на соответствие спецификации.

### Шаг 6. Генерируем стартовую миграцию ✅ ВЫПОЛНЕНО (04.11.2025)

**Чек-лист для Copilot**
- [x] Выполнить `alembic revision --autogenerate -m "initial_schema_phase1"`. ✅ Миграция `14c42e5d4b45` создана
- [x] Провести ручной рефактор SQL (добавить `CREATE EXTENSION IF NOT EXISTS vector`). ✅ Добавлено с проверкой диалекта
- [x] Обновить `.env` и `.env.sample` для PostgreSQL (localhost:5432, app_db). ✅ DATABASE_URL обновлён
- [x] Написать интеграционные тесты `tests/test_postgres_integration.py`. ✅ 9 тестов, все проходят
- [x] Создать утилиту `scripts/check_db_status.py` для диагностики БД. ✅ Показывает все таблицы, версии, размер

**Чек-лист для ручной проверки**
- [x] Запустить `alembic upgrade head` к PostgreSQL app_db. ✅ 12 таблиц созданы
- [x] Проверить установку pgvector 0.8.1. ✅ Расширение работает
- [x] Убедиться, что колонка `chunks.embedding` типа `vector(1536)`. ✅ Корректно
- [x] Проверить запись версии `14c42e5d4b45` в alembic_version. ✅ Записана
- [x] Запустить `pytest tests/test_postgres_integration.py -v`. ✅ 9/9 тестов прошли

**Результаты:**
- PostgreSQL 16.10 подключён и настроен
- pgvector 0.8.1 установлен и работает
- Все 12 таблиц созданы (users, sessions, documents, chunks, ai_conversations, ai_messages, search_history, api_keys, user_models, app_logs, job_queue, alembic_version)
- Каскадные удаления работают корректно (CASCADE)
- ENUM типы функционируют (user_role, document_status, message_role, log_level, job_type, job_status)
- Размер БД: 8.5 MB (пустая)

### Шаг 7. Реализуем слой репозиториев ✅

**Статус:** Завершено 04.11.2025  
**Коммит:** cda3efe5e139a3b2e9b5f6604e313b3a7af7276a

**Чек-лист для Copilot**
- [x] Создать `webapp/db/repositories/base.py` с generic `BaseRepository[ModelType]`.
- [x] Реализовать `UserRepository` (create_user, get_by_email, update_password).
- [x] Реализовать `DocumentRepository` (create_document, get_by_owner, update_status, mark_indexed).
- [x] Реализовать `ChunkRepository` (create_chunk, vector_search с pgvector, delete_by_document).
- [x] Добавить Python Enum классы (UserRole, DocumentStatus, MessageRole, LogLevel, JobType, JobStatus) в models.py.
- [x] Написать unit-тесты `tests/test_repositories.py`.

**Чек-лист для ручной проверки**
- [x] Запустить `pytest tests/test_repositories.py -v` (все тесты проходят).
- [x] Проверить vector_search на реальных данных с embeddings.
- [x] Убедиться, что репозитории не зависят от Flask context.

**Что сделано:**
- ✅ Создан каталог `webapp/db/repositories/` с базовым классом и 3 репозиториями
- ✅ `BaseRepository` — generic класс с CRUD (create, get_by_id, update, delete, find_one, find_all, count, exists)
- ✅ `UserRepository` — create_user, get_by_email, update_password, get_all_users
- ✅ `DocumentRepository` — create_document, get_by_owner, get_by_hash, update_status, mark_indexed, get_pending_documents, count_by_owner
- ✅ `ChunkRepository` — create_chunk, create_many, get_by_document, update_embedding, vector_search (pgvector cosine similarity), delete_by_document, count_by_document, get_chunks_without_embeddings
- ✅ Добавлены Python Enum классы в `models.py`: UserRole, DocumentStatus, MessageRole, LogLevel, JobType, JobStatus
- ✅ Исправлены несоответствия между репозиториями и моделями (owner_id, original_filename, text, chunk_idx)
- ✅ Написаны unit-тесты `tests/test_repositories.py` (13/13 passed)

**Примечания:**
- Репозитории не обращаются к Flask request, работают с чистыми SQLAlchemy сессиями
- ChunkRepository.vector_search использует pgvector cosine_distance для семантического поиска
- Все репозитории соответствуют спецификации из раздела 1.2

### Шаг 8. Включаем dual-mode адаптер ✅ ЗАВЕРШЁН

**Статус:** ✅ Завершено 04.11.2025  
**Коммит:** a697bca32292a6f04698f540adfba55ff7981988

**Чек-лист для Copilot**
- [x] Создать `webapp/services/data_access_adapter.py` с dual-mode поддержкой.
- [x] Интегрировать адаптер в `webapp/routes/search.py` (замена DocumentProcessor/Searcher).
- [x] Расширить тесты `tests/test_dual_mode_adapter.py` с Flask context.
- [x] Обновить `webapp/config/config_service.py` с Flask-совместимыми properties.
- [x] Исправить `webapp/__init__.py` для работы с singleton ConfigService.
- [x] Проверить параметр USE_DATABASE в .env.sample.
- [x] Протестировать запуск с USE_DATABASE=false (legacy mode).
- [x] Протестировать запуск с USE_DATABASE=true (DB mode).

**Чек-лист для ручной проверки**
- [x] Запустить `pytest tests/test_dual_mode_adapter.py -v` (17/19 passed, 2 skipped).
- [x] Запустить приложение с USE_DATABASE=false, проверить health endpoint.
- [x] Запустить приложение с USE_DATABASE=true, проверить health endpoint.
- [x] Убедиться, что оба режима не падают при старте.

**Что сделано:**
- ✅ Флаг `use_database` уже реализован в ConfigService (webapp/config/config_service.py, строка 146)
- ✅ Создан `webapp/services/data_access_adapter.py` с классом DataAccessAdapter (362 строки)
  - Методы: `build_index()`, `search_documents()`, `get_documents()`, `save_document()`, `delete_document()`
  - Поддержка dual-mode: `use_database=False` (legacy files) и `use_database=True` (PostgreSQL с fallback)
  - Использует модульный `logging.getLogger(__name__)` для независимости от Flask context
- ✅ Интегрирован в `webapp/routes/search.py`: 
  - Заменены прямые вызовы `DocumentProcessor()`/`Searcher()` на `adapter.build_index()` и `adapter.search_documents()`
  - Добавлена функция `_get_adapter()` для получения экземпляра адаптера
  - Сохранена обратная совместимость с legacy режимом
- ✅ Расширены тесты `tests/test_dual_mode_adapter.py` (406 строк, 17/19 passed, 2 skipped)
  - Добавлен `flask_app` fixture для тестирования с Flask context
  - Интеграционные тесты: `test_adapter_with_flask_context_files_mode`, `test_adapter_with_flask_context_db_mode_fallback`, `test_search_with_adapter_integration`
  - Skipped: `test_mode_switching_search_equivalence` (требует полной DB реализации), `test_build_index_route_integration` (требует полное Flask app)
- ✅ Обновлён `webapp/config/config_service.py`:
  - Добавлены Flask-совместимые properties: `UPLOAD_FOLDER`, `INDEX_FOLDER`, `LOGS_DIR`, `PROMPTS_FOLDER`, `SEARCH_RESULTS_FILE`
  - Добавлены `SECRET_KEY`, `JSON_AS_ASCII`, `MAX_CONTENT_LENGTH`, `REQUEST_TIMEOUT`, `LOG_FILE`, `LOG_LEVEL`, `LOG_BACKUP_COUNT`
- ✅ Исправлен `webapp/__init__.py`:
  - Изменён вызов `get_config(config_name)` на `get_config()` (singleton без параметров)
  - Исправлено: `app.config.from_object(config_service)` вместо `config_class`
- ✅ Параметр `USE_DATABASE` уже документирован в `.env.sample` (строки 62-65)
- ✅ Проверен запуск приложения с `USE_DATABASE=false` (legacy mode) — успешно, health endpoint работает
- ✅ Проверен запуск приложения с `USE_DATABASE=true` (DB mode) — успешно, health endpoint работает

**Изменённые файлы:**
1. `webapp/services/data_access_adapter.py` — создан, 362 строки
2. `webapp/routes/search.py` — интеграция adapter
3. `tests/test_dual_mode_adapter.py` — расширен до 406 строк, 17/19 тестов
4. `webapp/config/config_service.py` — добавлены Flask properties
5. `webapp/__init__.py` — исправлен вызов get_config()

**Примечания:**
- В DB режиме адаптер пока использует fallback к legacy методам (полная DB реализация — в следующих шагах)
- Оба режима стартуют без ошибок, health endpoint отвечает корректно
- ConfigService теперь полностью совместим с `app.config.from_object()`

### Шаг 9. Реализуем AuthService и JWT-поток

**Чек-лист для Copilot**
- [x] Создать `AuthService` с регистрацией, входом, валидацией пароля (bcrypt) и выдачей JWT.
- [ ] Добавить middleware, записывающее `request.user`.
- [x] Написать интеграционный тест `tests/test_auth_flow.py`.

**Чек-лист для ручной проверки**
- [x] Выполнить `pytest tests/test_auth_flow.py -q`.
- [ ] Проверить ручной вход через curl (`/auth/login`).
- [ ] Убедиться, что токен истекает согласно TTL и записывается в `sessions`.

### Шаг 10. Переносим API-ключи в БД

**Чек-лист для Copilot**
- [x] Создать репозиторий `ApiKeysRepository` и сервис для шифрования Fernet.
- [ ] Переписать `utils/api_keys_manager_multiple.py` на работу через БД.
- [x] Добавить тест `tests/test_api_keys_storage.py` с проверкой шифрования/расшифровки.

**Чек-лист для ручной проверки**
- [x] Запустить `pytest tests/test_api_keys_storage.py -q`.
- [ ] Добавить ключ через UI и убедиться, что в БД хранится ciphertext.
- [ ] Проверить, что маска ключа в UI отображается корректно.

### Шаг 11. Обновляем загрузку документов

**Чек-лист для Copilot**
- [x] Переписать маршруты `/upload` и связанные сервисы на работу с `documents` (bytea + sha256).
- [x] Добавить проверку размеров, MIME и дедупликации согласно разделу 2.1.
- [x] Написать интеграционный тест `tests/test_documents_upload_db.py`.

**Чек-лист для ручной проверки**
- [x] Выполнить `pytest tests/test_documents_upload_db.py -q`.
- [ ] Загрузить через UI документ >10 МБ и убедиться в корректной обработке.
- [ ] Проверить, что повторная загрузка идентичного файла не создаёт дубликат.

### Шаг 12. Индексация и pgvector

**Чек-лист для Copilot**
- [x] Перенести воркер индексации на чтение из БД и запись чанков/эмбеддингов в `chunks`.
- [x] Подключить pgvector и реализовать сохранение `embedding`.
- [x] Написать тест `tests/test_indexing_pgvector.py` (без OCR).

**Чек-лист для ручной проверки**
- [x] Выполнить `pytest tests/test_indexing_pgvector.py -q`.
- [ ] Проверить наличие индекса IVFFlat и параметров `lists`.
- [ ] Убедиться, что процесс индексации очищает временные файлы.

### Шаг 13. Обновляем поиск и историю

**Чек-лист для Copilot**
- [x] Реализовать `SearchService`, читающий из `chunks` и записывающий результаты в `search_history`.
- [x] Добавить гибридный поиск (keyword + semantic) с параметрами.
- [x] Написать тест `tests/test_search_service_db.py`.

**Чек-лист для ручной проверки**
- [x] Выполнить `pytest tests/test_search_service_db.py -q`.
- [ ] Проверить через UI, что выдача соответствует legacy индексу.
- [ ] Сравнить сниппеты с `_search_index.txt` для 2–3 документов.

### Шаг 14. Логирование и аудит

**Чек-лист для Copilot**
- [x] Внедрить `DatabaseLogHandler`, пишущий события в `app_logs`.
- [ ] Добавить middleware для аудита HTTP-запросов.
- [x] Написать тест `tests/test_logging_db.py`.

**Чек-лист для ручной проверки**
- [x] Выполнить `pytest tests/test_logging_db.py -q`.
- [ ] Создать искусственно ошибку и убедиться, что она попадает в `app_logs`.
- [x] Проверить наличие маскирования секретов в логах.

### Шаг 15. Финальный миграционный скрипт и документация

**Чек-лист для Copilot**
- [ ] Реализовать `scripts/migrate_files_to_db.py` с переносом `uploads/`, `index/api_keys.json`, `index/models.json`.
- [ ] Добавить `MIGRATION_GUIDE.md` и обновить `README.md` (раздел о запуске БД, dual-mode, rollback).
- [ ] Собрать `pytest -q` и smoke-тест `/health` на включенном `use_database`.

**Чек-лист для ручной проверки**
- [ ] Запустить миграционный скрипт на копии данных и сверить контрольные суммы.
- [ ] Пройти по руководству MIGRATION_GUIDE шаг за шагом.
- [ ] Сделать финальный ручной сценарий: загрузка документа → поиск → просмотр истории → выход.

---

## ПРИМЕЧАНИЕ: Внешняя инструкция от AI (04.11.2025)

**Получена инструкция для настройки БД**, содержащая:
- Модели: `Tender`, `Lot`, `Document`, `AnalysisResult` (закупки/тендеры)
- Схема `app`, структура `app/db.py`, `app/models.py`
- Настройка Alembic с `migrations/`

**РЕШЕНИЕ:** Инструкция относится к **другому проекту** (автоматизация тендерных закупок), не к текущему проекту web_interface.

**Наша реализация (инкремент 13):**
- ✅ Модели: `User`, `Session`, `Document`, `Chunk`, `AIConversation`, `AIMessage`, `SearchHistory`, `APIKey`, `UserModel`, `AppLog`, `JobQueue`
- ✅ Структура: `webapp/db/base.py`, `webapp/db/models.py`, `webapp/config/config_service.py`
- ✅ Alembic: `alembic/` (уже инициализирован)
- ✅ Схема по умолчанию (`public`)

**Статус:** Внешняя инструкция не применяется. Продолжаем выполнение инкремента 13 согласно утверждённой спецификации.